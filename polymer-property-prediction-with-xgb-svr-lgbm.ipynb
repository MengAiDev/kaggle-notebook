{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5e6e817",
   "metadata": {
    "papermill": {
     "duration": 0.015065,
     "end_time": "2025-08-03T15:41:48.723173",
     "exception": false,
     "start_time": "2025-08-03T15:41:48.708108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üß™Predicting Key Polymer Properties from Chemical Structure Using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1397efdf",
   "metadata": {
    "papermill": {
     "duration": 0.012668,
     "end_time": "2025-08-03T15:41:48.750769",
     "exception": false,
     "start_time": "2025-08-03T15:41:48.738101",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This work focuses on **developing machine learning models** to predict **fundamental polymer properties** directly from their chemical structures represented as `SMILES` strings. By leveraging a large-scale open dataset and advanced regression techniques, the goal is to accurately forecast five critical polymer metrics: `density`, glass transition temperature (`Tg`), thermal conductivity (`Tc`), radius of gyration (`Rg`), and fractional free volume (`FFV`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73862688",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:41:48.778292Z",
     "iopub.status.busy": "2025-08-03T15:41:48.777910Z",
     "iopub.status.idle": "2025-08-03T15:41:56.115471Z",
     "shell.execute_reply": "2025-08-03T15:41:56.114270Z"
    },
    "papermill": {
     "duration": 7.353596,
     "end_time": "2025-08-03T15:41:56.117458",
     "exception": false,
     "start_time": "2025-08-03T15:41:48.763862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install /kaggle/input/rdkit-install-whl/rdkit_wheel/rdkit_pypi-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f74279",
   "metadata": {
    "papermill": {
     "duration": 0.013342,
     "end_time": "2025-08-03T15:41:56.144661",
     "exception": false,
     "start_time": "2025-08-03T15:41:56.131319",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìöImports and Library Setup\n",
    "This section imports all the necessary libraries for data handling, visualization, preprocessing, modeling, evaluation, and other utilities used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aebd24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:41:56.173594Z",
     "iopub.status.busy": "2025-08-03T15:41:56.173238Z",
     "iopub.status.idle": "2025-08-03T15:42:01.956556Z",
     "shell.execute_reply": "2025-08-03T15:42:01.955574Z"
    },
    "papermill": {
     "duration": 5.800252,
     "end_time": "2025-08-03T15:42:01.958378",
     "exception": false,
     "start_time": "2025-08-03T15:41:56.158126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn: preprocessing, models, metrics, utilities\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold, RepeatedKFold, learning_curve\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#RDKit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Descriptors, Lipinski, rdMolDescriptors\n",
    "\n",
    "# optuna\n",
    "import optuna\n",
    "\n",
    "#Rich\n",
    "from rich.console import Console\n",
    "from rich.table import Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e50ddad",
   "metadata": {
    "papermill": {
     "duration": 0.013018,
     "end_time": "2025-08-03T15:42:01.984707",
     "exception": false,
     "start_time": "2025-08-03T15:42:01.971689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üì• Importing the Training Data¬∂\n",
    "I load the datasets `train.csv` and `test.csv` using `pandas.read_csv()`. The data is comma-separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec1e718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:02.013109Z",
     "iopub.status.busy": "2025-08-03T15:42:02.012616Z",
     "iopub.status.idle": "2025-08-03T15:42:02.062415Z",
     "shell.execute_reply": "2025-08-03T15:42:02.061529Z"
    },
    "papermill": {
     "duration": 0.066123,
     "end_time": "2025-08-03T15:42:02.064089",
     "exception": false,
     "start_time": "2025-08-03T15:42:01.997966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the training dataset from a CSV file\n",
    "df_train = pd.read_csv(\"/kaggle/input/neurips-open-polymer-prediction-2025/train.csv\", delimiter=',')\n",
    "\n",
    "# Load the test dataset from a CSV file\n",
    "df_test = pd.read_csv(\"/kaggle/input/neurips-open-polymer-prediction-2025/test.csv\", delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba07890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:02.158272Z",
     "iopub.status.busy": "2025-08-03T15:42:02.157894Z",
     "iopub.status.idle": "2025-08-03T15:42:02.186360Z",
     "shell.execute_reply": "2025-08-03T15:42:02.185299Z"
    },
    "papermill": {
     "duration": 0.044621,
     "end_time": "2025-08-03T15:42:02.187935",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.143314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576eb90b",
   "metadata": {
    "papermill": {
     "duration": 0.01542,
     "end_time": "2025-08-03T15:42:02.217510",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.202090",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üîçEDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c4dc0e",
   "metadata": {
    "papermill": {
     "duration": 0.013318,
     "end_time": "2025-08-03T15:42:02.244640",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.231322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üßπData Cleaning and Missing Values Analysis\n",
    "\n",
    "In this step, we start by removing the `'id'` column from the training dataset since it typically does not carry predictive information.\n",
    "\n",
    "Next, we display a summary of the training DataFrame, which includes data types, non-null counts, and memory usage, to get a general overview of the dataset.\n",
    "\n",
    "We then define a helper function `show_null` to calculate and print the percentage of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219993c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:02.274631Z",
     "iopub.status.busy": "2025-08-03T15:42:02.274337Z",
     "iopub.status.idle": "2025-08-03T15:42:02.306368Z",
     "shell.execute_reply": "2025-08-03T15:42:02.305396Z"
    },
    "papermill": {
     "duration": 0.048703,
     "end_time": "2025-08-03T15:42:02.308024",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.259321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop the 'id' column from the training DataFrame\n",
    "df_train = df_train.drop(\"id\", axis=1)\n",
    "\n",
    "# Display summary information about the DataFrame (column types, non-null counts, memory usage)\n",
    "df_train.info()\n",
    "\n",
    "# Define a function to display the percentage of missing values in each column\n",
    "def show_null(df):\n",
    "    null_stats = pd.DataFrame({\n",
    "        '%NaN': df.isna().mean() * 100  # Calculate percentage of missing values per column\n",
    "    })\n",
    "    print(null_stats)\n",
    "\n",
    "# Separator for better readability in output\n",
    "print(\"-------------------------------------------------------\")\n",
    "\n",
    "# Show missing value statistics for the training DataFrame\n",
    "show_null(df_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c23c48",
   "metadata": {
    "papermill": {
     "duration": 0.013698,
     "end_time": "2025-08-03T15:42:02.336374",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.322676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üìùInformation about features:\n",
    "* **id** - Unique identifier for each polymer.\n",
    "* **SMILES** - Sequence-like chemical notation representing polymer structures.\n",
    "* **Tg** - Glass transition temperature (¬∞C). **Target variable**.\n",
    "* **FFV** - Fractional free volume. **Target variable**.\n",
    "* **Tc** - Thermal conductivity (W/m¬∑K). **Target variable**.\n",
    "* **Density** - Polymer density (g/cm¬≥). **Target variable**.\n",
    "* **Rg** - Radius of gyration (√Ö). **Target variable**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5435c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:02.366138Z",
     "iopub.status.busy": "2025-08-03T15:42:02.365814Z",
     "iopub.status.idle": "2025-08-03T15:42:02.424753Z",
     "shell.execute_reply": "2025-08-03T15:42:02.423671Z"
    },
    "papermill": {
     "duration": 0.075984,
     "end_time": "2025-08-03T15:42:02.426483",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.350499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load supplemental dataset containing 'TC_mean' values (related to critical temperature)\n",
    "train_supplement_Tc = pd.read_csv(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset1.csv\", delimiter=',')\n",
    "\n",
    "# Rename the 'TC_mean' column to 'Tc' for consistency with the main dataset\n",
    "train_supplement_Tc['Tc'] = train_supplement_Tc['TC_mean']\n",
    "\n",
    "# Drop the original 'TC_mean' column after renaming\n",
    "train_supplement_Tc = train_supplement_Tc.drop(\"TC_mean\", axis=1)\n",
    "\n",
    "# Load supplemental dataset containing SMILES representations\n",
    "train_supplement_SMILES = pd.read_csv(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset2.csv\", delimiter=',')\n",
    "\n",
    "# Load supplemental dataset containing 'Tg' values (e.g., glass transition temperatures)\n",
    "train_supplement_Tg = pd.read_csv(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset3.csv\", delimiter=',')\n",
    "\n",
    "# Load supplemental dataset containing 'FFV' values (e.g., fractional free volume)\n",
    "train_supplement_FFV = pd.read_csv(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset4.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e298dd0",
   "metadata": {
    "papermill": {
     "duration": 0.013475,
     "end_time": "2025-08-03T15:42:02.454102",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.440627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This function groups a DataFrame by a specified column and computes the mean of another specified column within each group.\n",
    "\n",
    "- **Parameters:**\n",
    "  - `df`: Input pandas DataFrame.\n",
    "  - `group_by_column`: The column name to group the data by.\n",
    "  - `value_column`: The column name for which to calculate the mean.\n",
    "\n",
    "- **Returns:**\n",
    "  - A new DataFrame containing the group identifiers and their corresponding mean values.\n",
    "\n",
    "This is useful for aggregating data and summarizing values by categories or groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19e986e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:02.482507Z",
     "iopub.status.busy": "2025-08-03T15:42:02.482207Z",
     "iopub.status.idle": "2025-08-03T15:42:02.487486Z",
     "shell.execute_reply": "2025-08-03T15:42:02.486488Z"
    },
    "papermill": {
     "duration": 0.021285,
     "end_time": "2025-08-03T15:42:02.488985",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.467700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_group_mean(df, group_by_column, value_column):\n",
    "    \"\"\"\n",
    "    Groups the DataFrame by a specified column and calculates the mean of another column.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        group_by_column (str): Column to group by.\n",
    "        value_column (str): Column for which the mean will be calculated.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with the group-by column and the corresponding mean values.\n",
    "    \"\"\"\n",
    "    # Group and calculate the mean\n",
    "    grouped_mean = df.groupby(group_by_column)[value_column].mean().reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    grouped_mean.columns = [group_by_column, value_column]\n",
    "    \n",
    "    return grouped_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04721e47",
   "metadata": {
    "papermill": {
     "duration": 0.013556,
     "end_time": "2025-08-03T15:42:02.516432",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.502876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This function takes a list of `(name, dataframe)` tuples and prints a well-formatted table showing the number of rows in each DataFrame.\n",
    "\n",
    "- Utilizes the `rich` library's `Console` and `Table` for clear, colored output.\n",
    "- Displays DataFrame names alongside their row counts with thousands separators.\n",
    "- Helpful for quick inspection and comparison of dataset sizes during analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f3865e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:02.545252Z",
     "iopub.status.busy": "2025-08-03T15:42:02.544886Z",
     "iopub.status.idle": "2025-08-03T15:42:02.551247Z",
     "shell.execute_reply": "2025-08-03T15:42:02.550310Z"
    },
    "papermill": {
     "duration": 0.022478,
     "end_time": "2025-08-03T15:42:02.552653",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.530175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_row_counts(dfs):\n",
    "    \"\"\"\n",
    "    Nicely prints the number of rows for each DataFrame with column headers.\n",
    "    \n",
    "    :param dfs: A list of tuples in the format (dataframe_name, dataframe)\n",
    "    \"\"\"\n",
    "    console = Console()\n",
    "    table = Table(\n",
    "        title=\"Row Count per DataFrame\",\n",
    "        show_header=True,            # Show column headers\n",
    "        header_style=\"bold magenta\", # Style for headers\n",
    "        highlight=True,\n",
    "        show_lines=True              # Show lines between rows\n",
    "    )\n",
    "    \n",
    "    # Add columns with headers\n",
    "    table.add_column(\"DataFrame Name\", style=\"cyan\", justify=\"left\")\n",
    "    table.add_column(\"Row Count\", style=\"green\", justify=\"right\")\n",
    "    \n",
    "    for name, df in dfs:\n",
    "        table.add_row(name, f\"{df.shape[0]:,}\")\n",
    "    \n",
    "    console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59633acd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:02.582626Z",
     "iopub.status.busy": "2025-08-03T15:42:02.582313Z",
     "iopub.status.idle": "2025-08-03T15:42:02.601482Z",
     "shell.execute_reply": "2025-08-03T15:42:02.600410Z"
    },
    "papermill": {
     "duration": 0.036659,
     "end_time": "2025-08-03T15:42:02.603829",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.567170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create separate DataFrames for each target property, keeping only rows without missing values\n",
    "\n",
    "# Extract 'SMILES' and 'Tg' columns, drop rows with NaN, and reset index\n",
    "df_Tg = df_train[['SMILES', 'Tg']].dropna().reset_index(drop=True)\n",
    "\n",
    "# Extract 'SMILES' and 'FFV' columns, drop rows with NaN, and reset index\n",
    "df_FFV = df_train[['SMILES', 'FFV']].dropna().reset_index(drop=True)\n",
    "\n",
    "# Extract 'SMILES' and 'Tc' columns, drop rows with NaN, and reset index\n",
    "df_Tc = df_train[['SMILES', 'Tc']].dropna().reset_index(drop=True)\n",
    "\n",
    "# Extract 'SMILES' and 'Density' columns, drop rows with NaN, and reset index\n",
    "df_density = df_train[['SMILES', 'Density']].dropna().reset_index(drop=True)\n",
    "\n",
    "# Extract 'SMILES' and 'Rg' columns, drop rows with NaN, and reset index\n",
    "df_Rg = df_train[['SMILES', 'Rg']].dropna().reset_index(drop=True)\n",
    "\n",
    "# Combine all DataFrames with their corresponding task name\n",
    "dfs = [\n",
    "    ('Tg_train', df_Tg),\n",
    "    ('FFV_train', df_FFV),\n",
    "    ('Tc_train', df_Tc),\n",
    "    ('density_train', df_density),\n",
    "    ('Rg_train', df_Rg)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b3c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:02.634023Z",
     "iopub.status.busy": "2025-08-03T15:42:02.633644Z",
     "iopub.status.idle": "2025-08-03T15:42:02.647444Z",
     "shell.execute_reply": "2025-08-03T15:42:02.646421Z"
    },
    "papermill": {
     "duration": 0.03031,
     "end_time": "2025-08-03T15:42:02.649128",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.618818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_row_counts(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8300645e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:02.679422Z",
     "iopub.status.busy": "2025-08-03T15:42:02.679051Z",
     "iopub.status.idle": "2025-08-03T15:42:02.686454Z",
     "shell.execute_reply": "2025-08-03T15:42:02.685747Z"
    },
    "papermill": {
     "duration": 0.023922,
     "end_time": "2025-08-03T15:42:02.687968",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.664046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concatenate the original training DataFrames with the supplemental datasets to augment data\n",
    "# Add supplemental Tg data to the original Tg DataFrame, resetting the index\n",
    "df_Tg = pd.concat([df_Tg, train_supplement_Tg], ignore_index=True)\n",
    "\n",
    "# Add supplemental FFV data to the original FFV DataFrame, resetting the index\n",
    "df_FFV = pd.concat([df_FFV, train_supplement_FFV], ignore_index=True)\n",
    "\n",
    "# Add supplemental Tc data to the original Tc DataFrame, resetting the index\n",
    "df_Tc = pd.concat([df_Tc, train_supplement_Tc], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aafd0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:02.718025Z",
     "iopub.status.busy": "2025-08-03T15:42:02.717627Z",
     "iopub.status.idle": "2025-08-03T15:42:02.722731Z",
     "shell.execute_reply": "2025-08-03T15:42:02.721779Z"
    },
    "papermill": {
     "duration": 0.022548,
     "end_time": "2025-08-03T15:42:02.724565",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.702017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = [('Tg_train', df_Tg),\n",
    "      ('FFV_train', df_FFV),\n",
    "      ('Tc_train', df_Tc),\n",
    "      ('density_train', df_density),\n",
    "      ('Rg_train', df_Rg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e15ba5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:02.754381Z",
     "iopub.status.busy": "2025-08-03T15:42:02.753607Z",
     "iopub.status.idle": "2025-08-03T15:42:02.762972Z",
     "shell.execute_reply": "2025-08-03T15:42:02.762086Z"
    },
    "papermill": {
     "duration": 0.02568,
     "end_time": "2025-08-03T15:42:02.764416",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.738736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_row_counts(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa3e00f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:02.794663Z",
     "iopub.status.busy": "2025-08-03T15:42:02.794334Z",
     "iopub.status.idle": "2025-08-03T15:42:02.820875Z",
     "shell.execute_reply": "2025-08-03T15:42:02.819677Z"
    },
    "papermill": {
     "duration": 0.043439,
     "end_time": "2025-08-03T15:42:02.822780",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.779341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_Tg = calculate_group_mean(df_Tg, 'SMILES', 'Tg')\n",
    "df_FFV = calculate_group_mean(df_FFV, 'SMILES', 'FFV')\n",
    "df_Tc = calculate_group_mean(df_Tc, 'SMILES', 'Tc')\n",
    "df_density = calculate_group_mean(df_density, 'SMILES', 'Density')\n",
    "df_Rg = calculate_group_mean(df_Rg, 'SMILES', 'Rg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f743f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:02.852793Z",
     "iopub.status.busy": "2025-08-03T15:42:02.852453Z",
     "iopub.status.idle": "2025-08-03T15:42:02.862123Z",
     "shell.execute_reply": "2025-08-03T15:42:02.861314Z"
    },
    "papermill": {
     "duration": 0.026371,
     "end_time": "2025-08-03T15:42:02.863614",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.837243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = [('Tg_train', df_Tg),\n",
    "      ('FFV_train', df_FFV),\n",
    "      ('Tc_train', df_Tc),\n",
    "      ('density_train', df_density),\n",
    "      ('Rg_train', df_Rg)]\n",
    "print_row_counts(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b58a2",
   "metadata": {
    "papermill": {
     "duration": 0.014714,
     "end_time": "2025-08-03T15:42:02.892952",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.878238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## üìò **Molecular Descriptor Feature Engineering**\n",
    "\n",
    "This function generates a set of **physicochemical descriptors** from SMILES strings using RDKit. These descriptors can help machine learning models predict polymer properties such as **glass transition temperature (Tg)**, **density**, **free volume fraction (FFV)**, and more.\n",
    "\n",
    "Below are the descriptors used:\n",
    "\n",
    "* **MW (Molecular Weight)**: Heavier molecules often correlate with higher Tg and density.\n",
    "* **LogP (Partition Coefficient)**: Reflects hydrophobicity; can affect FFV and solubility.\n",
    "* **Rotatable Bonds**: More flexibility usually lowers Tg and increases conformational entropy.\n",
    "* **TPSA (Topological Polar Surface Area)**: Indicates polarity and hydrogen bonding potential; affects intermolecular interactions and Tc.\n",
    "* **FractionCSP3**: Fraction of sp¬≥-hybridized carbon atoms; higher values imply more saturation and potentially less rigidity.\n",
    "* **RingCount**: Number of rings; ring structures can increase rigidity and Tg.\n",
    "\n",
    "These features are simple to compute yet capture **key aspects of molecular structure**, making them valuable for data-driven property prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b4b04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:02.923855Z",
     "iopub.status.busy": "2025-08-03T15:42:02.923553Z",
     "iopub.status.idle": "2025-08-03T15:42:02.930353Z",
     "shell.execute_reply": "2025-08-03T15:42:02.929248Z"
    },
    "papermill": {
     "duration": 0.024166,
     "end_time": "2025-08-03T15:42:02.931910",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.907744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_features(row):\n",
    "    \"\"\"Extract molecular descriptors from a single row containing a SMILES string.\"\"\"\n",
    "    mol = Chem.MolFromSmiles(row['SMILES'])  # Convert SMILES to RDKit molecule\n",
    "    if mol is None:\n",
    "        return pd.Series({\n",
    "        'MW': 0, # Molecular Weight\n",
    "        'LogP': 0, # Hydrophobicity (Octanol-Water Partition Coefficient)\n",
    "        'RotBonds': 0, # Number of rotatable bonds\n",
    "        'TPSA': 0, # Topological Polar Surface Area\n",
    "        'FractionCSP3': 0, # Fraction of sp3 carbon atoms\n",
    "        'RingCount': 0 # Number of ring structures\n",
    "    })\n",
    "    # Compute basic molecular descriptors\n",
    "    return pd.Series({\n",
    "        'MW': Descriptors.MolWt(mol), # Molecular Weight\n",
    "        'LogP': Descriptors.MolLogP(mol), # Hydrophobicity (Octanol-Water Partition Coefficient)\n",
    "        'RotBonds': Lipinski.NumRotatableBonds(mol), # Number of rotatable bonds\n",
    "        'TPSA': Descriptors.TPSA(mol), # Topological Polar Surface Area\n",
    "        'FractionCSP3': rdMolDescriptors.CalcFractionCSP3(mol), # Fraction of sp3 carbon atoms\n",
    "        'RingCount': Lipinski.RingCount(mol) # Number of ring structures\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7326677a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:02.962694Z",
     "iopub.status.busy": "2025-08-03T15:42:02.962397Z",
     "iopub.status.idle": "2025-08-03T15:42:18.475136Z",
     "shell.execute_reply": "2025-08-03T15:42:18.474072Z"
    },
    "papermill": {
     "duration": 15.530002,
     "end_time": "2025-08-03T15:42:18.477079",
     "exception": false,
     "start_time": "2025-08-03T15:42:02.947077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_df = df_Tg.apply(create_features, axis=1)\n",
    "df_Tg = pd.concat([df_Tg, feature_df], axis=1)\n",
    "\n",
    "feature_df = df_Tc.apply(create_features, axis=1)\n",
    "df_Tc = pd.concat([df_Tc, feature_df], axis=1)\n",
    "\n",
    "feature_df = df_FFV.apply(create_features, axis=1)\n",
    "df_FFV = pd.concat([df_FFV, feature_df], axis=1)\n",
    "\n",
    "feature_df = df_density.apply(create_features, axis=1)\n",
    "df_density = pd.concat([df_density, feature_df], axis=1)\n",
    "\n",
    "feature_df = df_Rg.apply(create_features, axis=1)\n",
    "df_Rg = pd.concat([df_Rg, feature_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab0b95e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:18.509065Z",
     "iopub.status.busy": "2025-08-03T15:42:18.508169Z",
     "iopub.status.idle": "2025-08-03T15:42:18.521892Z",
     "shell.execute_reply": "2025-08-03T15:42:18.520915Z"
    },
    "papermill": {
     "duration": 0.030715,
     "end_time": "2025-08-03T15:42:18.523498",
     "exception": false,
     "start_time": "2025-08-03T15:42:18.492783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_Tg.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cffeca",
   "metadata": {
    "papermill": {
     "duration": 0.014313,
     "end_time": "2025-08-03T15:42:18.552631",
     "exception": false,
     "start_time": "2025-08-03T15:42:18.538318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üî¨Converting SMILES Strings to Morgan Fingerprints\n",
    "\n",
    "This code defines a function to convert molecular SMILES strings into fixed-length Morgan fingerprints using RDKit:\n",
    "\n",
    "- Initializes a Morgan fingerprint generator with radius 2 and 1024 bits.\n",
    "- `smiles_to_fp` function:\n",
    "  - Takes a SMILES string and an RDKit fingerprint generator.\n",
    "  - Converts the SMILES to an RDKit molecule object.\n",
    "  - Returns a zero vector if the SMILES is invalid.\n",
    "  - Otherwise, generates the fingerprint and returns it as a pandas Series.\n",
    "\n",
    "Morgan fingerprints are widely used to represent molecular structures numerically for machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4d8afe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:18.584543Z",
     "iopub.status.busy": "2025-08-03T15:42:18.583604Z",
     "iopub.status.idle": "2025-08-03T15:42:18.592427Z",
     "shell.execute_reply": "2025-08-03T15:42:18.591415Z"
    },
    "papermill": {
     "duration": 0.026635,
     "end_time": "2025-08-03T15:42:18.593980",
     "exception": false,
     "start_time": "2025-08-03T15:42:18.567345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
    "# Parameters for fingerprint generation\n",
    "NBITS = 1024\n",
    "\n",
    "# Initialize the Morgan fingerprint generators\n",
    "generator_r2 = GetMorganGenerator(radius=2, fpSize=NBITS)\n",
    "#generator_r3 = GetMorganGenerator(radius=3, fpSize=NBITS)\n",
    "\n",
    "def smiles_to_fp(smiles, generator):\n",
    "    \"\"\"\n",
    "    Converts a SMILES string to a Morgan fingerprint using a pre-initialized RDKit generator.\n",
    "    \n",
    "    Parameters:\n",
    "        smiles (str): SMILES representation of the molecule.\n",
    "        generator: An RDKit fingerprint generator (e.g., from GetMorganGenerator).\n",
    "        \n",
    "    Returns:\n",
    "        pd.Series: Fingerprint as a pandas Series. Returns zeros if SMILES is invalid.\n",
    "    \"\"\"\n",
    "    # Convert SMILES to RDKit molecule\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    \n",
    "    # Return a zero vector if the SMILES is invalid\n",
    "    if mol is None:\n",
    "        return np.zeros(NBITS)\n",
    "    \n",
    "    # Generate the fingerprint and convert it to a NumPy array\n",
    "    fp = generator.GetFingerprint(mol)\n",
    "    return pd.Series(np.array(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddced8d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:18.625213Z",
     "iopub.status.busy": "2025-08-03T15:42:18.624840Z",
     "iopub.status.idle": "2025-08-03T15:42:31.076534Z",
     "shell.execute_reply": "2025-08-03T15:42:31.075610Z"
    },
    "papermill": {
     "duration": 12.469262,
     "end_time": "2025-08-03T15:42:31.078241",
     "exception": false,
     "start_time": "2025-08-03T15:42:18.608979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_df(df):\n",
    "    feature_df_r2 = df['SMILES'].apply(lambda x: smiles_to_fp(x, generator_r2))\n",
    "    #feature_df_r3 = df['SMILES'].apply(lambda x: smiles_to_fp(x, generator_r3))\n",
    "    feature_df_r2.columns = [f'bit_{i+1}' for i in range(NBITS)]\n",
    "    #feature_df_r3.columns = [f'bit_{i+NBITS+1}' for i in range(NBITS)]\n",
    "    \n",
    "    df = df.drop('SMILES', axis = 1)\n",
    "    # Concatenate features with original DataFrame\n",
    "    return pd.concat([feature_df_r2, df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "df_Tg = create_df(df_Tg)\n",
    "\n",
    "df_FFV = create_df(df_FFV)\n",
    "\n",
    "df_Tc = create_df(df_Tc)\n",
    "\n",
    "df_density = create_df(df_density)\n",
    "\n",
    "df_Rg = create_df(df_Rg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea227c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:31.109086Z",
     "iopub.status.busy": "2025-08-03T15:42:31.108748Z",
     "iopub.status.idle": "2025-08-03T15:42:31.125583Z",
     "shell.execute_reply": "2025-08-03T15:42:31.124869Z"
    },
    "papermill": {
     "duration": 0.03392,
     "end_time": "2025-08-03T15:42:31.126837",
     "exception": false,
     "start_time": "2025-08-03T15:42:31.092917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_FFV.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d81182c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:31.162552Z",
     "iopub.status.busy": "2025-08-03T15:42:31.162222Z",
     "iopub.status.idle": "2025-08-03T15:42:31.198646Z",
     "shell.execute_reply": "2025-08-03T15:42:31.197765Z"
    },
    "papermill": {
     "duration": 0.057727,
     "end_time": "2025-08-03T15:42:31.200493",
     "exception": false,
     "start_time": "2025-08-03T15:42:31.142766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_Tg = df_Tg.drop(\"Tg\", axis = 1)\n",
    "X_FFV = df_FFV.drop(\"FFV\", axis = 1)\n",
    "X_Tc = df_Tc.drop(\"Tc\", axis = 1)\n",
    "X_Density = df_density.drop(\"Density\", axis = 1)\n",
    "X_Rg = df_Rg.drop(\"Rg\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74098eef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:31.233411Z",
     "iopub.status.busy": "2025-08-03T15:42:31.232471Z",
     "iopub.status.idle": "2025-08-03T15:42:31.237938Z",
     "shell.execute_reply": "2025-08-03T15:42:31.237005Z"
    },
    "papermill": {
     "duration": 0.024009,
     "end_time": "2025-08-03T15:42:31.239434",
     "exception": false,
     "start_time": "2025-08-03T15:42:31.215425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_Tg = df_Tg['Tg']\n",
    "Y_FFV = df_FFV['FFV']\n",
    "Y_Tc = df_Tc['Tc']\n",
    "Y_Density = df_density['Density']\n",
    "Y_Rg = df_Rg['Rg']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b93ea68",
   "metadata": {
    "papermill": {
     "duration": 0.020637,
     "end_time": "2025-08-03T15:42:31.276319",
     "exception": false,
     "start_time": "2025-08-03T15:42:31.255682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üîÄ Splitting the Dataset\n",
    "\n",
    "I separate the features (`Xdata`) and labels (`Ydata`) for model training.\n",
    "\n",
    "- The `Personality` column is selected as the target.\n",
    "- The rest of the DataFrame is used as input features.\n",
    "\n",
    "I then split the dataset into:\n",
    "\n",
    "- **Training set (50%)**\n",
    "- **Validation set (25%)**\n",
    "- **Test set (25%)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338bb528",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:31.325875Z",
     "iopub.status.busy": "2025-08-03T15:42:31.325482Z",
     "iopub.status.idle": "2025-08-03T15:42:31.331506Z",
     "shell.execute_reply": "2025-08-03T15:42:31.330600Z"
    },
    "papermill": {
     "duration": 0.037111,
     "end_time": "2025-08-03T15:42:31.333559",
     "exception": false,
     "start_time": "2025-08-03T15:42:31.296448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def spit_data(name, Xdata, Ydata, random_seed = 42):\n",
    "    # Split into training (80%) and test (20%)\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(Xdata, Ydata, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "    print(f\"----------------split for {name}_df----------------\")\n",
    "    # Print shapes of the splits\n",
    "    print(f\"Train shape, X: {Xtrain.shape}, y: {Ytrain.shape}\")\n",
    "    print(f\"Test shape, X: {Xtest.shape}, y: {Ytest.shape}\")\n",
    "    print()\n",
    "    return Xtrain, Xtest, Ytrain, Ytest\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb16b70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:31.374002Z",
     "iopub.status.busy": "2025-08-03T15:42:31.373111Z",
     "iopub.status.idle": "2025-08-03T15:42:31.451971Z",
     "shell.execute_reply": "2025-08-03T15:42:31.450405Z"
    },
    "papermill": {
     "duration": 0.097256,
     "end_time": "2025-08-03T15:42:31.453725",
     "exception": false,
     "start_time": "2025-08-03T15:42:31.356469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "X_Tg_Train, X_Tg_Test, Y_Tg_Train, Y_Tg_Test = spit_data(\"Tg\" ,X_Tg, Y_Tg)\n",
    "\n",
    "X_FFV_Train, X_FFV_Test, Y_FFV_Train, Y_FFV_Test = spit_data(\"FFV\" ,X_FFV, Y_FFV)\n",
    "\n",
    "X_Tc_Train, X_Tc_Test, Y_Tc_Train, Y_Tc_Test = spit_data(\"Tc\" ,X_Tc, Y_Tc)\n",
    "\n",
    "X_Density_Train, X_Density_Test, Y_Density_Train, Y_Density_Test = spit_data(\"density\" ,X_Density, Y_Density)\n",
    "\n",
    "X_Rg_Train, X_Rg_Test, Y_Rg_Train, Y_Rg_Test = spit_data(\"Rg\" ,X_Rg, Y_Rg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babda1ac",
   "metadata": {
    "papermill": {
     "duration": 0.016,
     "end_time": "2025-08-03T15:42:31.485108",
     "exception": false,
     "start_time": "2025-08-03T15:42:31.469108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üìäVisualizing Target Variable Distributions with Histograms and Mean Lines\n",
    "\n",
    "This code creates a multi-plot figure to visualize the distributions of different target variables in the training set:\n",
    "\n",
    "- Uses `seaborn` to plot histograms with KDE overlays for each target.\n",
    "- Adds a vertical dashed line marking the mean value of each distribution.\n",
    "- Places the mean value as a text label below the line for clarity.\n",
    "- Organizes subplots in a grid layout, dedicating the bottom row to the 'FFV' target spanning both columns.\n",
    "- Helps in understanding the spread and central tendency of each target variable's training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd1f6f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:31.516389Z",
     "iopub.status.busy": "2025-08-03T15:42:31.516035Z",
     "iopub.status.idle": "2025-08-03T15:42:33.303245Z",
     "shell.execute_reply": "2025-08-03T15:42:33.302357Z"
    },
    "papermill": {
     "duration": 1.806873,
     "end_time": "2025-08-03T15:42:33.306989",
     "exception": false,
     "start_time": "2025-08-03T15:42:31.500116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12,15), constrained_layout = True)\n",
    "spec = gridspec.GridSpec(nrows = 3, ncols = 2, figure = fig)\n",
    "\n",
    "dfs = [('Tg', Y_Tg_Train),\n",
    "      ('Rg', Y_Rg_Train),\n",
    "      ('Tc', Y_Tc_Train),\n",
    "      ('Density', Y_Density_Train),\n",
    "      ('FFV', Y_FFV_Train)]\n",
    "\n",
    "i = 0\n",
    "for name, df in dfs:\n",
    "    if name == 'FFV':\n",
    "        ax = fig.add_subplot(spec[2, :])\n",
    "    else:\n",
    "        ax = fig.add_subplot(spec[i // 2, i % 2])\n",
    "\n",
    "    mean = df.mean()\n",
    "\n",
    "    sns.histplot(df, kde = True, label = 'Histogram', bins = 14, color = \"cornflowerblue\")\n",
    "    ax.axvline(mean, color = 'darkorchid', linestyle = \"--\", linewidth = 2, label = 'Mean')\n",
    "\n",
    "    ax.text(mean, plt.ylim()[1]*(-0.1), f'{mean:.2f}', \n",
    "         ha='center', va='bottom', color='darkorchid',\n",
    "         bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "\n",
    "    ax.set_title(f\"Distribution of {name}(Train)\")\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Count/Density')\n",
    "\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    i+=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2474a873",
   "metadata": {
    "papermill": {
     "duration": 0.019247,
     "end_time": "2025-08-03T15:42:33.346845",
     "exception": false,
     "start_time": "2025-08-03T15:42:33.327598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üìà Target Variable Distributions ‚Äì Observations\n",
    "\n",
    "The following plots show the distributions of the five target properties from the training set:\n",
    "\n",
    "1. **Tg (Glass Transition Temperature)**\n",
    "- Appears slightly **right-skewed**, with a wide spread from negative to ~500.\n",
    "- The mean value is **~100.6**, marked by the purple dashed line.\n",
    "- Indicates significant variability in thermal behavior among the polymers.\n",
    "\n",
    "2. **Rg (Radius of Gyration)**\n",
    "- Also **right-skewed**, with values primarily concentrated between 10 and 25.\n",
    "- The mean is around **16.4**.\n",
    "- The tail suggests some polymers have relatively high chain flexibility or extension.\n",
    "\n",
    "3. **Tc (Crystallization Temperature)**\n",
    "- Strong **positive skew** with most values clustered between 0.1 and 0.4.\n",
    "- Mean value is approximately **0.26**.\n",
    "- Many polymers do not crystallize easily or crystallize at low temperatures.\n",
    "\n",
    "4. **Density**\n",
    "- Shows a **right-skewed** distribution centered near **0.99**.\n",
    "- Most values are between 0.8 and 1.1, typical for organic polymer materials.\n",
    "- The long tail toward higher densities might reflect highly packed or crosslinked structures.\n",
    "\n",
    "5. **FFV (Fractional Free Volume)**\n",
    "- **Approximately normal distribution** centered at **0.37**.\n",
    "- Symmetric shape suggests more stable variance in FFV across polymers.\n",
    "- FFV may be a more predictable target for regression tasks compared to others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5a224f",
   "metadata": {
    "papermill": {
     "duration": 0.019252,
     "end_time": "2025-08-03T15:42:33.385845",
     "exception": false,
     "start_time": "2025-08-03T15:42:33.366593",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üìäNormality Assessment of FFV Target Variable\n",
    "\n",
    "The **QQ-plot** visualizes how closely the fractional free volume (`FFV`) training data follows a normal distribution. Points aligning along the reference line indicate normality. \n",
    "\n",
    "Additionally, the Shapiro-Wilk test statistically evaluates the normality of the data. A high `p-value` (typically > 0.05) suggests that the null hypothesis of normality cannot be rejected, implying the data is approximately normally distributed. Conversely, a low p-value indicates deviation from normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d382c0c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:33.426963Z",
     "iopub.status.busy": "2025-08-03T15:42:33.426607Z",
     "iopub.status.idle": "2025-08-03T15:42:35.651061Z",
     "shell.execute_reply": "2025-08-03T15:42:35.649995Z"
    },
    "papermill": {
     "duration": 2.247146,
     "end_time": "2025-08-03T15:42:35.652637",
     "exception": false,
     "start_time": "2025-08-03T15:42:33.405491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sm.qqplot(Y_FFV_Train, line='s')\n",
    "plt.title(\"QQ-Plot for FFV\")\n",
    "plt.show()\n",
    "\n",
    "# Shapiro-Wilk Test\n",
    "shapiro_stat, shapiro_p = stats.shapiro(Y_FFV_Train)\n",
    "print(f\"Shapiro-Wilk test: statistic={shapiro_stat:.4f}, p-value={shapiro_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fe54c8",
   "metadata": {
    "papermill": {
     "duration": 0.020502,
     "end_time": "2025-08-03T15:42:35.694018",
     "exception": false,
     "start_time": "2025-08-03T15:42:35.673516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "üß™ **Shapiro‚ÄìWilk Test Interpretation:**\n",
    "\n",
    "* **Test Statistic:** 0.9028\n",
    "* **p-value:** 3.41 √ó 10‚Åª‚Åµ‚Å∑\n",
    "\n",
    "The Shapiro‚ÄìWilk test checks the null hypothesis that the data is drawn from a **normal distribution**.\n",
    "\n",
    "Since the **p-value is extremely small (much less than 0.05)**, we **strongly reject H‚ÇÄ**.\n",
    "This means that **the distribution of FFV is not normal**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a9fb49",
   "metadata": {
    "papermill": {
     "duration": 0.020532,
     "end_time": "2025-08-03T15:42:35.735481",
     "exception": false,
     "start_time": "2025-08-03T15:42:35.714949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "üîç **What the Q-Q plot shows**:\n",
    "The center of the distribution (near 0 on the x-axis) lies almost perfectly on the red line - indicating a good fit to the normal distribution in the middle part.\n",
    "\n",
    "The tails deviate a bit:\n",
    "\n",
    "* Left: the lower quantiles are slightly lower than the theoretical ones ‚Üí a small \"left tail\".\n",
    "\n",
    "* Right: upper quantiles are strongly above the theoretical ones ‚Üí right \"heavy\" tail (typical case of slight asymmetry or right \"fat\" side)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0f7760",
   "metadata": {
    "papermill": {
     "duration": 0.020392,
     "end_time": "2025-08-03T15:42:35.776501",
     "exception": false,
     "start_time": "2025-08-03T15:42:35.756109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üìäDistribution Analysis of Numeric Features in Training Data\n",
    "\n",
    "This visualization presents `histograms` with **KDE** overlays for several numeric feature columns combined from different training subsets:\n",
    "\n",
    "- Shows the distribution of molecular descriptors like `molecular weight` (MW), `LogP`, `number of rotatable bonds`, `TPSA`, `fraction of sp3 carbons`, and `ring count`.\n",
    "- Marks the mean value for each feature with a dashed red vertical line and annotates the exact mean below the line.\n",
    "- Arranged in a grid layout to easily compare distributions side-by-side.\n",
    "- Useful for understanding feature ranges and central tendencies across the combined training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72abcb76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:35.820268Z",
     "iopub.status.busy": "2025-08-03T15:42:35.819691Z",
     "iopub.status.idle": "2025-08-03T15:42:38.020227Z",
     "shell.execute_reply": "2025-08-03T15:42:38.019294Z"
    },
    "papermill": {
     "duration": 2.226837,
     "end_time": "2025-08-03T15:42:38.024073",
     "exception": false,
     "start_time": "2025-08-03T15:42:35.797236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xtrain_combined = pd.concat([X_Tg_Train, X_FFV_Train, X_Tc_Train, X_Density_Train, X_Rg_Train])\n",
    "\n",
    "fig = plt.figure(figsize = (15,13), constrained_layout = True)\n",
    "\n",
    "spec = gridspec.GridSpec(nrows = 3, ncols = 2, figure = fig)\n",
    "\n",
    "target_cols = ['MW', 'LogP', 'RotBonds', 'TPSA', 'FractionCSP3', 'RingCount']\n",
    "\n",
    "for i, col in enumerate(target_cols):\n",
    "    ax = fig.add_subplot(spec[i//2, i%2])\n",
    "\n",
    "    mean = Xtrain_combined[col].mean()\n",
    "    sns.histplot(Xtrain_combined[col], kde=True, label = 'Histogram', bins = 14, color = \"darkorange\")\n",
    "\n",
    "    ax.axvline(mean, linestyle ='--', color = \"red\", linewidth = 2, label = 'Mean')\n",
    "\n",
    "    ax.text(mean, plt.ylim()[1]*(-0.15), f'{mean:.2f}', \n",
    "         ha='center', va='bottom', color='red',\n",
    "         bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "\n",
    "    ax.set_title(f\"Distribution of {col}(Train)\")\n",
    "\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Count/Density')\n",
    "\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5de0e3",
   "metadata": {
    "papermill": {
     "duration": 0.024475,
     "end_time": "2025-08-03T15:42:38.073447",
     "exception": false,
     "start_time": "2025-08-03T15:42:38.048972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üìà Molecular Feature Distributions ‚Äî Summary & Insights\n",
    "\n",
    "The histograms above represent the distributions of several molecular descriptors extracted from SMILES strings using RDKit. These descriptors can provide valuable structural and physicochemical information for polymer property prediction tasks (e.g. Tg, Tc, Density, FFV, Rg). Here's what we observe:\n",
    "\n",
    "1. **Molecular Weight (MW)**\n",
    "- Distribution is **right-skewed**, with most molecules below ~600 g/mol.\n",
    "- A long tail suggests presence of heavier, possibly more complex structures.\n",
    "- Mean ‚âà **423.6**.\n",
    "\n",
    "2. **LogP (Octanol-Water Partition Coefficient)**\n",
    "- Appears to follow a **nearly normal distribution**, centered around ~5.5.\n",
    "- Suggests a balanced lipophilic/hydrophilic profile in many compounds.\n",
    "- Extreme LogP values may indicate unusual solubility characteristics.\n",
    "\n",
    "3. **Rotatable Bonds (RotBonds)**\n",
    "- Strong **right skew** ‚Äî most molecules have < 10 rotatable bonds.\n",
    "- A few outliers (up to ~80) indicate flexible or large chain-like structures.\n",
    "- Flexibility can correlate with properties like Tg and Rg.\n",
    "  \n",
    "4. **Topological Polar Surface Area (TPSA)**\n",
    "- Again, **right-skewed** with many small values and a few high ones (>200).\n",
    "- High TPSA may indicate increased polarity or hydrogen bonding potential.\n",
    "- Mean ‚âà **62**, which is relatively moderate.\n",
    "\n",
    "5. **Fraction of sp¬≥ Carbons (FractionCSP3)**\n",
    "- Shows a **bimodal trend**, with peaks near 0 and 1.\n",
    "- Indicates presence of both highly aromatic and fully saturated compounds.\n",
    "- May relate to polymer rigidity and branching.\n",
    "\n",
    "6. **Ring Count**\n",
    "- Majority of molecules have **fewer than 5 rings**, with a sharp drop-off.\n",
    "- Right-skewed again, with occasional polycyclic compounds.\n",
    "- Rings influence molecular rigidity, possibly impacting properties like density or FFV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2745f464",
   "metadata": {
    "papermill": {
     "duration": 0.025163,
     "end_time": "2025-08-03T15:42:38.123200",
     "exception": false,
     "start_time": "2025-08-03T15:42:38.098037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üîóCorrelation Matrix of Numeric Features\n",
    "\n",
    "In this step, we calculate the **correlation matrix** for the selected numeric target columns in the training dataset. Correlation measures the strength and direction of the linear relationship between pairs of variables.\n",
    "\n",
    "- `Xtrain_combined[target_cols].corr()` computes the correlation matrix.\n",
    "- We then visualize the matrix using a **heatmap** with `seaborn`:\n",
    "  - `annot=True` displays the correlation values on the heatmap.\n",
    "  - `cmap=\"coolwarm\"` applies a diverging color palette for better interpretation.\n",
    "  - `fmt=\".2f\"` formats the correlation values to two decimal places.\n",
    "\n",
    "This visualization helps identify strong positive or negative correlations between features, which can be useful for feature selection or multicollinearity analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec30d63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:38.174272Z",
     "iopub.status.busy": "2025-08-03T15:42:38.173858Z",
     "iopub.status.idle": "2025-08-03T15:42:38.491456Z",
     "shell.execute_reply": "2025-08-03T15:42:38.490537Z"
    },
    "papermill": {
     "duration": 0.34517,
     "end_time": "2025-08-03T15:42:38.493161",
     "exception": false,
     "start_time": "2025-08-03T15:42:38.147991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr = Xtrain_combined[target_cols].corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Matrix of correlations of numeric features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc83d79",
   "metadata": {
    "papermill": {
     "duration": 0.025534,
     "end_time": "2025-08-03T15:42:38.546485",
     "exception": false,
     "start_time": "2025-08-03T15:42:38.520951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üîóCorrelation of Numeric Features with Target Variables\n",
    "\n",
    "In this section, we compute and display the correlation between several **numeric features** and different **target variables**. The results are presented in a formatted table using the **Rich** library for better visualization in the console.\n",
    "\n",
    "Steps:\n",
    "- Define:\n",
    "  - `targets`: list of target variables (e.g., Tg, Tc, FFV, etc.).\n",
    "  - `numeric_cols`: list of numeric feature columns.\n",
    "  - `dfs_X`: corresponding feature datasets for each target.\n",
    "  - `Ys`: corresponding target series for each dataset.\n",
    "- Create a Rich `Table` with:\n",
    "  - A title and headers for the target and feature names.\n",
    "  - Color styling (`cyan` for targets, `green` for features).\n",
    "- For each target:\n",
    "  - Compute Pearson correlation (`df_X[col].corr(Y)`) between each numeric feature and the target.\n",
    "  - Add the results as a row in the table.\n",
    "- Print the table using `console.print()`.\n",
    "\n",
    "This table provides a quick comparison of how strongly each numeric feature correlates with each target, which is helpful for **feature importance assessment** and **model input selection**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75169a67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:38.600349Z",
     "iopub.status.busy": "2025-08-03T15:42:38.599978Z",
     "iopub.status.idle": "2025-08-03T15:42:38.631132Z",
     "shell.execute_reply": "2025-08-03T15:42:38.630205Z"
    },
    "papermill": {
     "duration": 0.05998,
     "end_time": "2025-08-03T15:42:38.632659",
     "exception": false,
     "start_time": "2025-08-03T15:42:38.572679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = ['Tg', 'Tc', 'FFV', 'Density', 'Rg']\n",
    "numeric_cols = ['MW', 'LogP', 'RotBonds', 'TPSA', 'FractionCSP3', 'RingCount']\n",
    "dfs_X = [X_Tg_Train, X_Rg_Train, X_Tc_Train, X_Density_Train, X_FFV_Train]\n",
    "Ys = [Y_Tg_Train, Y_Rg_Train, Y_Tc_Train, Y_Density_Train, Y_FFV_Train]\n",
    "\n",
    "console = Console()\n",
    "table = Table(\n",
    "    title=\"Correlations of numeric features with target variables\",\n",
    "    show_header=True,\n",
    "    header_style=\"bold magenta\",\n",
    "    highlight=True,\n",
    "    show_lines=True\n",
    ")\n",
    "table.add_column(\"Target Name\", style=\"cyan\", justify=\"left\")\n",
    "\n",
    "for col_name in numeric_cols:\n",
    "    table.add_column(col_name, style=\"green\", justify=\"right\")\n",
    "\n",
    "# Cycle through targets and datasets\n",
    "for target_name, df_X, Y in zip(targets, dfs_X, Ys):\n",
    "    correlations = [f\"{df_X[col].corr(Y):.3f}\" for col in numeric_cols]\n",
    "    table.add_row(target_name, *correlations)\n",
    "\n",
    "console.print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2959ec76",
   "metadata": {
    "papermill": {
     "duration": 0.026623,
     "end_time": "2025-08-03T15:42:38.686207",
     "exception": false,
     "start_time": "2025-08-03T15:42:38.659584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚öôÔ∏èModels tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8420f4",
   "metadata": {
    "papermill": {
     "duration": 0.026891,
     "end_time": "2025-08-03T15:42:38.739980",
     "exception": false,
     "start_time": "2025-08-03T15:42:38.713089",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üéØObjective Function for XGBoost Hyperparameter Optimization (Optuna)\n",
    "\n",
    "This function defines the **objective function** for hyperparameter tuning of an XGBoost regressor using **Optuna**. The goal is to optimize model parameters to minimize the cross-validated error.\n",
    "\n",
    "Key steps:\n",
    "- **Parameter Sampling**: Using `trial.suggest_*` methods, we define the search space for:\n",
    "  - `n_estimators`: number of boosting rounds.\n",
    "  - `max_depth`: depth of each tree.\n",
    "  - `learning_rate`: shrinkage factor for weights (sampled logarithmically).\n",
    "  - `subsample`: fraction of samples used for each tree.\n",
    "  - `colsample_bytree`: fraction of features per tree.\n",
    "  - `gamma`: minimum loss reduction for further partitioning.\n",
    "  - `reg_alpha` and `reg_lambda`: L1 and L2 regularization terms.\n",
    "  - `min_child_weight`: minimum sum of instance weights per child.\n",
    "- **Model Setup**: Create an `XGBRegressor` with the sampled parameters.\n",
    "- **Cross-Validation**:\n",
    "  - Use `KFold` with 5 splits (shuffled) for performance evaluation.\n",
    "  - Metric: `neg_mean_absolute_error` (negative MAE, as required by Optuna).\n",
    "- **Scoring**: Uses negative mean absolute error (`neg_mean_absolute_error`) for Optuna compatibility.\n",
    "- **Return Objective**: Mean cross-validation score is returned for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa103ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:38.794654Z",
     "iopub.status.busy": "2025-08-03T15:42:38.794344Z",
     "iopub.status.idle": "2025-08-03T15:42:38.801347Z",
     "shell.execute_reply": "2025-08-03T15:42:38.800207Z"
    },
    "papermill": {
     "duration": 0.036396,
     "end_time": "2025-08-03T15:42:38.803032",
     "exception": false,
     "start_time": "2025-08-03T15:42:38.766636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective_xgb(trial, X, y):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 600),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 1, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 5, 20),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 5, 20),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 5, 15),\n",
    "        'random_state': 42,\n",
    "        'tree_method': 'hist'  \n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBRegressor(**params)\n",
    "\n",
    "    #if X.shape[0] < 1000:\n",
    "    #    cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "    #else:\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring = 'neg_mean_absolute_error')\n",
    "\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843328ff",
   "metadata": {
    "papermill": {
     "duration": 0.027144,
     "end_time": "2025-08-03T15:42:38.857920",
     "exception": false,
     "start_time": "2025-08-03T15:42:38.830776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üéØObjective Function for LightGBM Hyperparameter Optimization (Optuna)\n",
    "\n",
    "This function defines the **objective function** for tuning a LightGBM regressor using **Optuna**. The goal is to find the best hyperparameters to minimize the cross-validated mean absolute error.\n",
    "\n",
    "Highlights:\n",
    "- **Hyperparameter Search Space** includes:\n",
    "  - `n_estimators`: number of boosting iterations.\n",
    "  - `max_depth`: maximum tree depth.\n",
    "  - `learning_rate`: step size shrinkage (log scale).\n",
    "  - `num_leaves`: maximum number of leaves in one tree.\n",
    "  - `subsample` (bagging fraction) and `colsample_bytree` (feature fraction) for sampling data and features.\n",
    "  - Regularization parameters `reg_alpha` and `reg_lambda` with log-scaled search.\n",
    "  - `min_child_samples`: minimum number of data points in a leaf.\n",
    "- **Model Setup**: Creates a `LGBMRegressor` with the sampled parameters, setting random seed and enabling parallel jobs.\n",
    "- **Cross-Validation**: Uses 5-fold KFold with shuffling to evaluate performance.\n",
    "- **Scoring**: Uses negative mean absolute error (`neg_mean_absolute_error`) for Optuna compatibility.\n",
    "- **Return Objective**: Mean cross-validation score is returned for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f332fd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:38.913609Z",
     "iopub.status.busy": "2025-08-03T15:42:38.913286Z",
     "iopub.status.idle": "2025-08-03T15:42:43.793172Z",
     "shell.execute_reply": "2025-08-03T15:42:43.792129Z"
    },
    "papermill": {
     "duration": 4.910129,
     "end_time": "2025-08-03T15:42:43.795032",
     "exception": false,
     "start_time": "2025-08-03T15:42:38.884903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "def objective_lgbm(trial, X, y):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 550),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 8),  \n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 40, 100),  \n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # bagging_fraction\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),  # feature_fraction\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-6, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-6, 10.0, log=True),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'boosting_type': 'gbdt'\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params, verbose = -1)\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_absolute_error')\n",
    "    \n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaf2ba8",
   "metadata": {
    "papermill": {
     "duration": 0.027498,
     "end_time": "2025-08-03T15:42:43.850624",
     "exception": false,
     "start_time": "2025-08-03T15:42:43.823126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üéØSupport Vector Regression (SVR) with Validation Curves for Hyperparameter Tuning\n",
    "\n",
    "This function evaluates the effect of the **regularization parameter `C`** on the performance of an SVR model with an RBF kernel, using different values of the **epsilon (`Œµ`)** parameter.\n",
    "\n",
    "Key points:\n",
    "- Data scaling:\n",
    "  - The model is tested on both **unscaled** and **standard scaled** versions of the training data.\n",
    "- `validation_curve` from `sklearn` is used to compute training and validation scores over a range of `C` values (`param_range`).\n",
    "- `epsilon` controls the margin of tolerance where no penalty is given to errors.\n",
    "- For each `epsilon` in `[0.0005, 0.001, 0.01, 0.1]`:\n",
    "  - A subplot shows the validation curve plotting **MAE** (mean absolute error) against `C` on a logarithmic scale.\n",
    "  - Both training and validation errors are displayed to visualize potential overfitting or underfitting.\n",
    "- The plots help identify the optimal `C` value and the impact of data scaling on model performance.\n",
    "\n",
    "This detailed visualization guides the selection of hyperparameters for SVR, improving generalization on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d73b99e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:43.907431Z",
     "iopub.status.busy": "2025-08-03T15:42:43.906731Z",
     "iopub.status.idle": "2025-08-03T15:42:43.916385Z",
     "shell.execute_reply": "2025-08-03T15:42:43.915193Z"
    },
    "papermill": {
     "duration": 0.039637,
     "end_time": "2025-08-03T15:42:43.917796",
     "exception": false,
     "start_time": "2025-08-03T15:42:43.878159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "def SVR_fit(Xtrain, Ytrain):\n",
    "    scaler = StandardScaler()\n",
    "    Xtrain_scaled = scaler.fit_transform(Xtrain)\n",
    "    eps = [0.0005, 0.001, 0.01, 0.1]\n",
    "    param_range = np.logspace(-4, 3, 10)\n",
    "    Xdata = [('no scaler', Xtrain),\n",
    "            ('standard scaler', Xtrain_scaled)]\n",
    "    for name, X in Xdata:\n",
    "        print(f\"-------------------------------------with {name}-------------------------------------\")\n",
    "        fig = plt.figure(figsize=(15,13), constrained_layout = True)\n",
    "\n",
    "        spec = gridspec.GridSpec(nrows = 2, ncols = 2, figure = fig)\n",
    "        for i, epsilon in enumerate(eps):\n",
    "            ax = fig.add_subplot(spec[i//2, i%2])\n",
    "            model = SVR(kernel='rbf', epsilon = epsilon)\n",
    "            train_scores, valid_scores = validation_curve(\n",
    "                model, X, Ytrain,\n",
    "                param_name=\"C\",\n",
    "                param_range=param_range,\n",
    "                cv=5,  \n",
    "                scoring=\"neg_mean_absolute_error\"\n",
    "            )\n",
    "    \n",
    "            train_scores_mean = -train_scores.mean(axis=1)\n",
    "            valid_scores_mean = -valid_scores.mean(axis=1)\n",
    "    \n",
    "            ax.semilogx(param_range, train_scores_mean, label=\"Train\", color=\"blue\")\n",
    "            ax.semilogx(param_range, valid_scores_mean, label=\"Validation\", color=\"orange\")\n",
    "            ax.set_xlabel(\"C\")\n",
    "            ax.set_ylabel(\"MAE\")\n",
    "            ax.grid(True)\n",
    "            ax.set_title(f\"Validation curve for SVR(eps = {epsilon})\")\n",
    "            ax.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8a8df6",
   "metadata": {
    "papermill": {
     "duration": 0.026316,
     "end_time": "2025-08-03T15:42:43.971810",
     "exception": false,
     "start_time": "2025-08-03T15:42:43.945494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üéØObjective Function for Random Forest Hyperparameter Optimization (Optuna)\n",
    "\n",
    "This function defines an **objective function** to optimize hyperparameters of a `RandomForestRegressor` using **Optuna**.\n",
    "\n",
    "Details:\n",
    "- **Hyperparameters tuned:**\n",
    "  - `n_estimators`: number of trees in the forest.\n",
    "  - `max_depth`: maximum depth of each tree.\n",
    "  - `min_samples_split`: minimum samples required to split an internal node.\n",
    "  - `min_samples_leaf`: minimum samples required at a leaf node.\n",
    "  - `max_features`: number of features to consider when looking for the best split; chosen from categorical options (`sqrt`, `log2`, 0.8, 1).\n",
    "- **Cross-validation strategy:**\n",
    "  - If dataset is small (< 1000 samples), use `RepeatedKFold` with 5 splits and 3 repeats for more robust evaluation.\n",
    "  - Otherwise, use standard shuffled `KFold` with 5 splits.\n",
    "- **Scoring metric:** negative mean absolute error (`neg_mean_absolute_error`), compatible with Optuna.\n",
    "- The function returns the mean cross-validation score, which Optuna tries to maximize.\n",
    "\n",
    "This function supports systematic tuning of Random Forest parameters to improve regression performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50b0b7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:44.026884Z",
     "iopub.status.busy": "2025-08-03T15:42:44.026548Z",
     "iopub.status.idle": "2025-08-03T15:42:44.034250Z",
     "shell.execute_reply": "2025-08-03T15:42:44.032997Z"
    },
    "papermill": {
     "duration": 0.037232,
     "end_time": "2025-08-03T15:42:44.035967",
     "exception": false,
     "start_time": "2025-08-03T15:42:43.998735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective_rf(trial, X, y):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 5, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 5, 20),\n",
    "        'max_features': trial.suggest_categorical('max_features', [ 'sqrt', 'log2', 0.8, 1]),\n",
    "        'random_state': 42,\n",
    "    }\n",
    "\n",
    "    model = RandomForestRegressor(**params)\n",
    "\n",
    "    if X.shape[0] < 1000:\n",
    "        cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "    else:\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            \n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring = 'neg_mean_absolute_error')\n",
    "\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6658f7e",
   "metadata": {
    "papermill": {
     "duration": 0.027721,
     "end_time": "2025-08-03T15:42:44.092559",
     "exception": false,
     "start_time": "2025-08-03T15:42:44.064838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üß†Plotting Learning Curves to Monitor Overfitting and Model Performance\n",
    "\n",
    "This function plots the **learning curve** of a regression model, showing how training and validation errors evolve as the size of the training data increases.\n",
    "\n",
    "Key points:\n",
    "- Uses 5-fold shuffled cross-validation to evaluate model performance at different training set sizes.\n",
    "- Tracks **mean absolute error (MAE)** on both training and validation sets.\n",
    "- The plot helps monitor **overfitting**:\n",
    "  - If the training error is much lower than validation error and the gap doesn't close with more data, the model is likely overfitting.\n",
    "  - If training and validation errors converge and remain low, the model generalizes well.\n",
    "- Allows assessment of whether adding more training data could improve validation performance or if the model complexity needs adjustment.\n",
    "\n",
    "This visualization is essential for ensuring the model is not overfitting and for guiding decisions on model tuning or data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e8a587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:44.149689Z",
     "iopub.status.busy": "2025-08-03T15:42:44.149340Z",
     "iopub.status.idle": "2025-08-03T15:42:44.156972Z",
     "shell.execute_reply": "2025-08-03T15:42:44.155990Z"
    },
    "papermill": {
     "duration": 0.036847,
     "end_time": "2025-08-03T15:42:44.158529",
     "exception": false,
     "start_time": "2025-08-03T15:42:44.121682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_learning_curve(Xdata, Ydata, model, name):\n",
    "    fig = plt.figure(figsize = (8,6), constrained_layout = True)\n",
    "    \n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "    \n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        model,\n",
    "        Xdata,\n",
    "        Ydata,\n",
    "        cv = cv,\n",
    "        scoring = 'neg_mean_absolute_error',\n",
    "        train_sizes = np.linspace(0.1,1.0,10),\n",
    "        n_jobs = -1\n",
    "    )\n",
    "\n",
    "    train_scores_mean = -np.mean(train_scores, axis = 1)\n",
    "    val_scores_mean = - np.mean(val_scores, axis = 1)\n",
    "\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color = 'blue', label = 'Train error')\n",
    "    plt.plot(train_sizes, val_scores_mean, 'o-', color = 'orange', label = 'Validation error')\n",
    "    plt.xlabel('Training size')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title(f'Learning curve for {name}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afea9a73",
   "metadata": {
    "papermill": {
     "duration": 0.028391,
     "end_time": "2025-08-03T15:42:44.214746",
     "exception": false,
     "start_time": "2025-08-03T15:42:44.186355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üî•Tg + XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc618a83",
   "metadata": {
    "papermill": {
     "duration": 0.027065,
     "end_time": "2025-08-03T15:42:44.269236",
     "exception": false,
     "start_time": "2025-08-03T15:42:44.242171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code runs an Optuna study to maximize the cross-validated score by tuning XGBoost hyperparameters over 50 trials. After optimization, it prints the best-found parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3653d55f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:42:44.325968Z",
     "iopub.status.busy": "2025-08-03T15:42:44.325472Z",
     "iopub.status.idle": "2025-08-03T15:51:19.147500Z",
     "shell.execute_reply": "2025-08-03T15:51:19.146247Z"
    },
    "papermill": {
     "duration": 514.852941,
     "end_time": "2025-08-03T15:51:19.149139",
     "exception": false,
     "start_time": "2025-08-03T15:42:44.296198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_xgb = optuna.create_study(direction = 'maximize')\n",
    "study_xgb.optimize(lambda trial : objective_xgb(trial, X_Tg_Train, Y_Tg_Train), n_trials=50)\n",
    "#'exact'\n",
    "print(\"The best paramters for XGBoost:\")\n",
    "print(study_xgb.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390fbebd",
   "metadata": {
    "papermill": {
     "duration": 0.030543,
     "end_time": "2025-08-03T15:51:19.210053",
     "exception": false,
     "start_time": "2025-08-03T15:51:19.179510",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "An `XGBoost` regressor is instantiated using the best hyperparameters found earlier, trained on the training data, and the training mean absolute error (MAE) is printed to evaluate fit quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124e31a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:51:19.273936Z",
     "iopub.status.busy": "2025-08-03T15:51:19.273597Z",
     "iopub.status.idle": "2025-08-03T15:51:21.347372Z",
     "shell.execute_reply": "2025-08-03T15:51:21.344425Z"
    },
    "papermill": {
     "duration": 2.107972,
     "end_time": "2025-08-03T15:51:21.349704",
     "exception": false,
     "start_time": "2025-08-03T15:51:19.241732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_Tg = xgb.XGBRegressor(\n",
    "    n_estimators = 504,\n",
    "    max_depth = 3,\n",
    "    learning_rate = 0.022748903648379455,\n",
    "    subsample =0.5150950623784505,\n",
    "    colsample_bytree = 0.8136028949107683,\n",
    "    gamma =  1.7296216677361642,\n",
    "    reg_alpha =  7.759582933382447,\n",
    "    reg_lambda = 10.899776530374172,\n",
    "    min_child_weight = 4,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "model_Tg.fit(X_Tg_Train, Y_Tg_Train)\n",
    "print(mean_absolute_error(Y_Tg_Train, model_Tg.predict(X_Tg_Train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e44ad51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:51:21.415311Z",
     "iopub.status.busy": "2025-08-03T15:51:21.414496Z",
     "iopub.status.idle": "2025-08-03T15:51:59.945213Z",
     "shell.execute_reply": "2025-08-03T15:51:59.944115Z"
    },
    "papermill": {
     "duration": 38.593638,
     "end_time": "2025-08-03T15:51:59.977691",
     "exception": false,
     "start_time": "2025-08-03T15:51:21.384053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_learning_curve(X_Tg_Train, Y_Tg_Train, model_Tg, 'Tg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7742db6b",
   "metadata": {
    "papermill": {
     "duration": 0.03202,
     "end_time": "2025-08-03T15:52:00.043395",
     "exception": false,
     "start_time": "2025-08-03T15:52:00.011375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üî•TC + SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca23dec",
   "metadata": {
    "papermill": {
     "duration": 0.030537,
     "end_time": "2025-08-03T15:52:00.104712",
     "exception": false,
     "start_time": "2025-08-03T15:52:00.074175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This command runs the `SVR_fit` function on the training data for the target `Tc`. It generates validation curves for different values of the SVR `epsilon` parameter, comparing training and validation errors across a range of regularization strengths (`C`) with and without feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9043cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:52:00.169206Z",
     "iopub.status.busy": "2025-08-03T15:52:00.168853Z",
     "iopub.status.idle": "2025-08-03T15:54:35.072700Z",
     "shell.execute_reply": "2025-08-03T15:54:35.071579Z"
    },
    "papermill": {
     "duration": 154.978544,
     "end_time": "2025-08-03T15:54:35.114584",
     "exception": false,
     "start_time": "2025-08-03T15:52:00.136040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SVR_fit(X_Tc_Train, Y_Tc_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d8ca06",
   "metadata": {
    "papermill": {
     "duration": 0.037456,
     "end_time": "2025-08-03T15:54:35.189036",
     "exception": false,
     "start_time": "2025-08-03T15:54:35.151580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The `SVR` model is trained using the parameters `C=50` and `epsilon=0.01`, which were chosen based on the validation curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81984fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:54:35.266633Z",
     "iopub.status.busy": "2025-08-03T15:54:35.266303Z",
     "iopub.status.idle": "2025-08-03T15:54:35.900414Z",
     "shell.execute_reply": "2025-08-03T15:54:35.898902Z"
    },
    "papermill": {
     "duration": 0.675011,
     "end_time": "2025-08-03T15:54:35.902065",
     "exception": false,
     "start_time": "2025-08-03T15:54:35.227054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_Tc = SVR(kernel='rbf', C = 115, epsilon = 0.01)\n",
    "model_Tc.fit(X_Tc_Train, Y_Tc_Train)\n",
    "print(mean_absolute_error(Y_Tc_Train, model_Tc.predict(X_Tc_Train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0dee6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:54:35.985335Z",
     "iopub.status.busy": "2025-08-03T15:54:35.984987Z",
     "iopub.status.idle": "2025-08-03T15:54:41.503541Z",
     "shell.execute_reply": "2025-08-03T15:54:41.502504Z"
    },
    "papermill": {
     "duration": 5.560432,
     "end_time": "2025-08-03T15:54:41.505211",
     "exception": false,
     "start_time": "2025-08-03T15:54:35.944779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_learning_curve(X_Tc_Train, Y_Tc_Train, model_Tc, 'TC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c365308c",
   "metadata": {
    "papermill": {
     "duration": 0.041286,
     "end_time": "2025-08-03T15:54:41.587014",
     "exception": false,
     "start_time": "2025-08-03T15:54:41.545728",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üî•FFV + LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459ab141",
   "metadata": {
    "papermill": {
     "duration": 0.040169,
     "end_time": "2025-08-03T15:54:41.670258",
     "exception": false,
     "start_time": "2025-08-03T15:54:41.630089",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code performs hyperparameter tuning for a `LightGBM` model over 50 trials to maximize validation performance. The best parameters found are then printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a6db7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:54:41.751941Z",
     "iopub.status.busy": "2025-08-03T15:54:41.751580Z",
     "iopub.status.idle": "2025-08-03T15:58:22.847929Z",
     "shell.execute_reply": "2025-08-03T15:58:22.846991Z"
    },
    "papermill": {
     "duration": 221.139257,
     "end_time": "2025-08-03T15:58:22.849553",
     "exception": false,
     "start_time": "2025-08-03T15:54:41.710296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_lgbm = optuna.create_study(direction = 'maximize')\n",
    "study_lgbm.optimize(lambda trial : objective_lgbm(trial, X_FFV_Train, Y_FFV_Train), n_trials=50)\n",
    "#'exact'\n",
    "print(\"The best paramters for LGBM:\")\n",
    "print(study_lgbm.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6201b3a3",
   "metadata": {
    "papermill": {
     "duration": 0.042032,
     "end_time": "2025-08-03T15:58:22.932999",
     "exception": false,
     "start_time": "2025-08-03T15:58:22.890967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The `LightGBM` regressor is instantiated with the best-tuned parameters and trained on the **FFV** dataset. The training mean absolute error (MAE) is printed to assess model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaac459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:58:23.020346Z",
     "iopub.status.busy": "2025-08-03T15:58:23.019899Z",
     "iopub.status.idle": "2025-08-03T15:58:24.624985Z",
     "shell.execute_reply": "2025-08-03T15:58:24.623942Z"
    },
    "papermill": {
     "duration": 1.651564,
     "end_time": "2025-08-03T15:58:24.626538",
     "exception": false,
     "start_time": "2025-08-03T15:58:22.974974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_FFV = lgb.LGBMRegressor(\n",
    "    n_estimators = 548,\n",
    "    max_depth = 8,\n",
    "    learning_rate = 0.07285429805216179,\n",
    "    num_leaves = 51,\n",
    "    subsample =0.9186429709788774,\n",
    "    colsample_bytree = 0.8451398289748779,\n",
    "    reg_alpha =0.011786753567576962,\n",
    "    reg_lambda =2.226162826179684e-08,\n",
    "    min_child_samples = 11,\n",
    "    random_state =  42,\n",
    "    boosting_type = 'gbdt',\n",
    "    verbose = -1\n",
    ")\n",
    "\n",
    "model_FFV.fit(X_FFV_Train, Y_FFV_Train)\n",
    "print(mean_absolute_error(Y_FFV_Train, model_FFV.predict(X_FFV_Train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45161de0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T15:58:24.712009Z",
     "iopub.status.busy": "2025-08-03T15:58:24.711578Z",
     "iopub.status.idle": "2025-08-03T16:00:41.978402Z",
     "shell.execute_reply": "2025-08-03T16:00:41.977257Z"
    },
    "papermill": {
     "duration": 137.35606,
     "end_time": "2025-08-03T16:00:42.024710",
     "exception": false,
     "start_time": "2025-08-03T15:58:24.668650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_learning_curve(X_FFV_Train, Y_FFV_Train, model_FFV, 'FFV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a344fab",
   "metadata": {
    "papermill": {
     "duration": 0.042634,
     "end_time": "2025-08-03T16:00:42.109699",
     "exception": false,
     "start_time": "2025-08-03T16:00:42.067065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üî•Density + LBGM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6c2ad",
   "metadata": {
    "papermill": {
     "duration": 0.043002,
     "end_time": "2025-08-03T16:00:42.196580",
     "exception": false,
     "start_time": "2025-08-03T16:00:42.153578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code performs hyperparameter tuning for a `LightGBM` model over 50 trials to maximize validation performance. The best parameters found are then printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef77b03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T16:00:42.285229Z",
     "iopub.status.busy": "2025-08-03T16:00:42.284869Z",
     "iopub.status.idle": "2025-08-03T16:01:16.439365Z",
     "shell.execute_reply": "2025-08-03T16:01:16.438408Z"
    },
    "papermill": {
     "duration": 34.20135,
     "end_time": "2025-08-03T16:01:16.441018",
     "exception": false,
     "start_time": "2025-08-03T16:00:42.239668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_lgb = optuna.create_study(direction = 'maximize')\n",
    "study_lgb.optimize(lambda trial : objective_lgbm(trial, X_Density_Train, Y_Density_Train), n_trials=50)\n",
    "#'exact'\n",
    "print(\"The best paramters for LGBM:\")\n",
    "print(study_lgb.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5e8d7",
   "metadata": {
    "papermill": {
     "duration": 0.045785,
     "end_time": "2025-08-03T16:01:16.534410",
     "exception": false,
     "start_time": "2025-08-03T16:01:16.488625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The `LightGBM` regressor is instantiated with the best-tuned parameters and trained on the **Density** dataset. The training mean absolute error (MAE) is printed to assess model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286b3516",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T16:01:16.630695Z",
     "iopub.status.busy": "2025-08-03T16:01:16.630341Z",
     "iopub.status.idle": "2025-08-03T16:01:16.787337Z",
     "shell.execute_reply": "2025-08-03T16:01:16.785968Z"
    },
    "papermill": {
     "duration": 0.207641,
     "end_time": "2025-08-03T16:01:16.788957",
     "exception": false,
     "start_time": "2025-08-03T16:01:16.581316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_Density = lgb.LGBMRegressor(\n",
    "    n_estimators = 445,\n",
    "    max_depth = 3,\n",
    "    learning_rate = 0.03005975330148901,\n",
    "    num_leaves = 78,\n",
    "    subsample =0.7020942819679887,\n",
    "    colsample_bytree = 0.7844462554278813,\n",
    "    reg_alpha = 0.0004484916008774172,\n",
    "    reg_lambda =0.0005698184260493566,\n",
    "    min_child_samples = 5,\n",
    "    random_state =  42,\n",
    "    boosting_type = 'gbdt',\n",
    "    verbose = -1\n",
    ")\n",
    "\n",
    "model_Density.fit(X_Density_Train, Y_Density_Train)\n",
    "print(mean_absolute_error(Y_Density_Train, model_Density.predict(X_Density_Train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6f3906",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T16:01:16.882300Z",
     "iopub.status.busy": "2025-08-03T16:01:16.881973Z",
     "iopub.status.idle": "2025-08-03T16:01:25.640062Z",
     "shell.execute_reply": "2025-08-03T16:01:25.638934Z"
    },
    "papermill": {
     "duration": 8.806415,
     "end_time": "2025-08-03T16:01:25.641545",
     "exception": false,
     "start_time": "2025-08-03T16:01:16.835130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_learning_curve(X_Density_Train, Y_Density_Train, model_Density, 'Density')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cf6706",
   "metadata": {
    "papermill": {
     "duration": 0.04726,
     "end_time": "2025-08-03T16:01:25.736302",
     "exception": false,
     "start_time": "2025-08-03T16:01:25.689042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üî•RG + LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff17bb5b",
   "metadata": {
    "papermill": {
     "duration": 0.047144,
     "end_time": "2025-08-03T16:01:25.831458",
     "exception": false,
     "start_time": "2025-08-03T16:01:25.784314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code performs hyperparameter tuning for a `LightGBM` model over 50 trials to maximize validation performance. The best parameters found are then printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63952e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T16:01:25.927811Z",
     "iopub.status.busy": "2025-08-03T16:01:25.927515Z",
     "iopub.status.idle": "2025-08-03T16:02:12.995870Z",
     "shell.execute_reply": "2025-08-03T16:02:12.994648Z"
    },
    "papermill": {
     "duration": 47.118461,
     "end_time": "2025-08-03T16:02:12.997487",
     "exception": false,
     "start_time": "2025-08-03T16:01:25.879026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "study_lgb = optuna.create_study(direction = 'maximize')\n",
    "study_lgb.optimize(lambda trial : objective_lgbm(trial, X_Rg_Train, Y_Rg_Train), n_trials=50)\n",
    "#'exact'\n",
    "print(\"The best paramters for LGBM:\")\n",
    "print(study_lgb.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99514377",
   "metadata": {
    "papermill": {
     "duration": 0.04846,
     "end_time": "2025-08-03T16:02:13.094881",
     "exception": false,
     "start_time": "2025-08-03T16:02:13.046421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The `LightGBM` regressor is instantiated with the best-tuned parameters and trained on the **Rg** dataset. The training mean absolute error (MAE) is printed to assess model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b71c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T16:02:13.197816Z",
     "iopub.status.busy": "2025-08-03T16:02:13.197505Z",
     "iopub.status.idle": "2025-08-03T16:02:13.336730Z",
     "shell.execute_reply": "2025-08-03T16:02:13.335455Z"
    },
    "papermill": {
     "duration": 0.192675,
     "end_time": "2025-08-03T16:02:13.338538",
     "exception": false,
     "start_time": "2025-08-03T16:02:13.145863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_Rg = lgb.LGBMRegressor(\n",
    "    n_estimators = 417,\n",
    "    max_depth = 3,\n",
    "    learning_rate = 0.0223696041817692,\n",
    "    num_leaves = 85,\n",
    "    subsample =0.6316470850414286,\n",
    "    colsample_bytree = 0.8396247783719049,\n",
    "    reg_alpha = 4.306437129417159e-06,\n",
    "    reg_lambda =0.011339773998675985,\n",
    "    min_child_samples = 7,\n",
    "    random_state =  42,\n",
    "    boosting_type = 'gbdt'\n",
    ")\n",
    "\n",
    "model_Rg.fit(X_Rg_Train, Y_Rg_Train)\n",
    "print(mean_absolute_error(Y_Rg_Train, model_Rg.predict(X_Rg_Train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87195c23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T16:02:13.441214Z",
     "iopub.status.busy": "2025-08-03T16:02:13.440023Z",
     "iopub.status.idle": "2025-08-03T16:02:20.385462Z",
     "shell.execute_reply": "2025-08-03T16:02:20.384387Z"
    },
    "papermill": {
     "duration": 6.999451,
     "end_time": "2025-08-03T16:02:20.387853",
     "exception": false,
     "start_time": "2025-08-03T16:02:13.388402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_learning_curve(X_Rg_Train, Y_Rg_Train, model_Rg, 'Rg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc22686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T16:02:20.492701Z",
     "iopub.status.busy": "2025-08-03T16:02:20.492388Z",
     "iopub.status.idle": "2025-08-03T16:02:20.498423Z",
     "shell.execute_reply": "2025-08-03T16:02:20.497398Z"
    },
    "papermill": {
     "duration": 0.059127,
     "end_time": "2025-08-03T16:02:20.500047",
     "exception": false,
     "start_time": "2025-08-03T16:02:20.440920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_models = [model_Tg, model_FFV, model_Tc, model_Density, model_Rg]\n",
    "col_names = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
    "all_X_Train = [X_Tg_Train, X_FFV_Train, X_Tc_Train, X_Density_Train, X_Rg_Train]\n",
    "all_X_Test = [X_Tg_Test, X_FFV_Test, X_Tc_Test, X_Density_Test, X_Rg_Test]\n",
    "\n",
    "all_Y_Train = [Y_Tg_Train, Y_FFV_Train, Y_Tc_Train, Y_Density_Train, Y_Rg_Train]\n",
    "all_Y_Test = [Y_Tg_Test, Y_FFV_Test, Y_Tc_Test, Y_Density_Test, Y_Rg_Test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbd1dd7",
   "metadata": {
    "papermill": {
     "duration": 0.053097,
     "end_time": "2025-08-03T16:02:20.605585",
     "exception": false,
     "start_time": "2025-08-03T16:02:20.552488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## üìäPlotting Learning Curves for Multiple Models\n",
    "\n",
    "This code generates learning curves for several models across different target variables, displaying how training and validation errors (MAE) evolve with increasing training set sizes.\n",
    "\n",
    "Details:\n",
    "- Uses 5-fold shuffled cross-validation for robust evaluation.\n",
    "- Plots are arranged in a 3x2 grid for clear comparison.\n",
    "- Each subplot shows training and validation MAE against training size for one model.\n",
    "- Helps to visually assess model generalization and detect overfitting or underfitting across multiple targets at once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ef378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T16:02:20.710311Z",
     "iopub.status.busy": "2025-08-03T16:02:20.709909Z",
     "iopub.status.idle": "2025-08-03T16:05:22.782383Z",
     "shell.execute_reply": "2025-08-03T16:05:22.781281Z"
    },
    "papermill": {
     "duration": 182.185776,
     "end_time": "2025-08-03T16:05:22.844007",
     "exception": false,
     "start_time": "2025-08-03T16:02:20.658231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve, KFold\n",
    "\n",
    "fig = plt.figure(figsize = (18,15), constrained_layout = True)\n",
    "\n",
    "spec = gridspec.GridSpec(nrows = 3, ncols = 2, figure = fig)\n",
    "i = 0\n",
    "for name, model, X_train, Y_train in zip(col_names, all_models, all_X_Train, all_Y_Train):\n",
    "    cv = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        model,\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        cv = cv,\n",
    "        scoring = 'neg_mean_absolute_error',\n",
    "        train_sizes = np.linspace(0.1,1.0,10),\n",
    "        n_jobs = -1\n",
    "    )\n",
    "\n",
    "    train_scores_mean = -np.mean(train_scores, axis = 1)\n",
    "    val_scores_mean = - np.mean(val_scores, axis = 1)\n",
    "\n",
    "    ax = fig.add_subplot(spec[i//2, i%2])\n",
    "\n",
    "    ax.plot(train_sizes, train_scores_mean, 'o-', color = 'blue', label = 'Train error')\n",
    "    ax.plot(train_sizes, val_scores_mean, 'o-', color = 'orange', label = 'Validation error')\n",
    "    ax.set_xlabel('Training size')\n",
    "    ax.set_ylabel('MAE')\n",
    "    ax.set_title(f'Learning curve for {name}')\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    i+=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea495708",
   "metadata": {
    "papermill": {
     "duration": 0.054601,
     "end_time": "2025-08-03T16:05:22.952277",
     "exception": false,
     "start_time": "2025-08-03T16:05:22.897676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚öñÔ∏èComputing Weighted Mean Absolute Error (wMAE) Across Multiple Models\n",
    "\n",
    "This function calculates a **weighted mean absolute error (wMAE)** for a set of regression models and datasets, accounting for differences in sample sizes and target ranges.\n",
    "\n",
    "Key points:\n",
    "- For each target/property:\n",
    "  - `n_i`: number of samples.\n",
    "  - `r_i`: range of target values (max - min).\n",
    "- Weights `w_i` are computed to balance the influence of each target, normalizing by range and adjusting for sample size.\n",
    "- The total weighted absolute error is computed as the sum of weighted absolute errors from all models.\n",
    "- Final wMAE normalizes the total weighted error by the total number of samples.\n",
    "- Returns both the overall wMAE and the list of weights used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d3adb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T16:05:23.061951Z",
     "iopub.status.busy": "2025-08-03T16:05:23.061651Z",
     "iopub.status.idle": "2025-08-03T16:05:23.069276Z",
     "shell.execute_reply": "2025-08-03T16:05:23.068391Z"
    },
    "papermill": {
     "duration": 0.06446,
     "end_time": "2025-08-03T16:05:23.070723",
     "exception": false,
     "start_time": "2025-08-03T16:05:23.006263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_wmae(all_models, all_X_Data, all_Y_Data):\n",
    "    K = len(all_models)\n",
    "    \n",
    "    # Counting n_i and r_i for each property\n",
    "    n_values = [len(y) for y in all_Y_Data]\n",
    "    r_values = [y.max() - y.min() for y in all_Y_Data]\n",
    "    \n",
    "    # Calculate the denominator for the second part of the formula\n",
    "    denominator = sum(np.sqrt(1 / np.array(n_values)))\n",
    "    \n",
    "    # Calculate weights w_i\n",
    "    weights = []\n",
    "    for i in range(K):\n",
    "        w_i = (1 / r_values[i]) * ((K * np.sqrt(1 / n_values[i])) / denominator)\n",
    "        weights.append(w_i)\n",
    "    \n",
    "    # Calculate wMAE\n",
    "    total_error = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    for i, (model, X_data, Y_data) in enumerate(zip(all_models, all_X_Data, all_Y_Data)):\n",
    "        y_pred = model.predict(X_data)\n",
    "        mae_i = np.abs(y_pred - Y_data).sum()\n",
    "        total_error += weights[i] * mae_i\n",
    "        total_count += len(Y_data)\n",
    "    \n",
    "    wmae = total_error / total_count\n",
    "    return wmae, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80da6f17",
   "metadata": {
    "papermill": {
     "duration": 0.053034,
     "end_time": "2025-08-03T16:05:23.178313",
     "exception": false,
     "start_time": "2025-08-03T16:05:23.125279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Calculating and Printing Weighted `wMAE` for **Train** and **Test** Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae9e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T16:05:23.287479Z",
     "iopub.status.busy": "2025-08-03T16:05:23.287084Z",
     "iopub.status.idle": "2025-08-03T16:05:24.087865Z",
     "shell.execute_reply": "2025-08-03T16:05:24.086685Z"
    },
    "papermill": {
     "duration": 0.85724,
     "end_time": "2025-08-03T16:05:24.089428",
     "exception": false,
     "start_time": "2025-08-03T16:05:23.232188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "wmae_train, _ = compute_wmae(all_models, all_X_Train, all_Y_Train)\n",
    "wmae_test, _ = compute_wmae(all_models, all_X_Test, all_Y_Test)\n",
    "\n",
    "print(f\"wMAE for Train data: {wmae_train}, wMAE for Test data: {wmae_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4b3aba",
   "metadata": {
    "papermill": {
     "duration": 0.055792,
     "end_time": "2025-08-03T16:05:24.199761",
     "exception": false,
     "start_time": "2025-08-03T16:05:24.143969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚úÖFinal Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f41239b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T16:05:24.312731Z",
     "iopub.status.busy": "2025-08-03T16:05:24.312394Z",
     "iopub.status.idle": "2025-08-03T16:05:24.652383Z",
     "shell.execute_reply": "2025-08-03T16:05:24.651329Z"
    },
    "papermill": {
     "duration": 0.397916,
     "end_time": "2025-08-03T16:05:24.654238",
     "exception": false,
     "start_time": "2025-08-03T16:05:24.256322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_df = df_test.apply(create_features, axis = 1)\n",
    "df_test = pd.concat([df_test, feature_df], axis = 1)\n",
    "df_test = create_df(df_test)\n",
    "\n",
    "test_id = df_test[\"id\"]\n",
    "df_test = df_test.drop(\"id\", axis = 1)\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission[\"id\"] = test_id\n",
    "for model, col in zip(all_models, col_names):\n",
    "    submission[col] = model.predict(df_test)\n",
    "submission    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4377a2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T16:05:24.765720Z",
     "iopub.status.busy": "2025-08-03T16:05:24.765399Z",
     "iopub.status.idle": "2025-08-03T16:05:24.775959Z",
     "shell.execute_reply": "2025-08-03T16:05:24.775115Z"
    },
    "papermill": {
     "duration": 0.068348,
     "end_time": "2025-08-03T16:05:24.777641",
     "exception": false,
     "start_time": "2025-08-03T16:05:24.709293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index = False, sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249eb64b",
   "metadata": {
    "papermill": {
     "duration": 0.054903,
     "end_time": "2025-08-03T16:05:24.888877",
     "exception": false,
     "start_time": "2025-08-03T16:05:24.833974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ‚úÖSummary\n",
    "\n",
    "In this first version of the pipeline, I implemented five separate regression models for the target properties:\n",
    "\n",
    "* **XGBoost** for *Tg*\n",
    "* **SVR** for *Tc*\n",
    "* **LightGBM** for *FFV*, *Density*, and *Rg*\n",
    "\n",
    "For training, I used three of the provided datasets (excluding the one containing only SMILES). Combining these sources might improve predictive accuracy on the test set, although the opposite effect is also possible due to potential data distribution differences.\n",
    "\n",
    "Additionally, I incorporated molecular descriptors such as **MW**, **LogP**, **RotBonds**, **TPSA**, **FractionCSP3**, and **RingCount**, which were computed using **RDKit** based on the SMILES representations.\n",
    "\n",
    "Thank you for reviewing my submission! I‚Äôd be happy to receive any comments and advice since I‚Äôm just beginning my journey in machine learning. I‚Äôll keep working on optimizing the models and exploring additional features in future versions :)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12966160,
     "sourceId": 74608,
     "sourceType": "competition"
    },
    {
     "datasetId": 7678913,
     "sourceId": 12191182,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1423.913279,
   "end_time": "2025-08-03T16:05:27.569520",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-03T15:41:43.656241",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
