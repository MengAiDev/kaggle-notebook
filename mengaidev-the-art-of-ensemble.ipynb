{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MODEL GEMMA2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007012,
     "end_time": "2025-07-23T09:27:23.310372",
     "exception": false,
     "start_time": "2025-07-23T09:27:23.30336",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:33:54.550144Z",
     "iopub.status.busy": "2025-07-26T10:33:54.549936Z",
     "iopub.status.idle": "2025-07-26T10:33:54.556776Z",
     "shell.execute_reply": "2025-07-26T10:33:54.556292Z",
     "shell.execute_reply.started": "2025-07-26T10:33:54.550118Z"
    },
    "papermill": {
     "duration": 0.016342,
     "end_time": "2025-07-23T09:27:23.33404",
     "exception": false,
     "start_time": "2025-07-23T09:27:23.317698",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "VER=1\n",
    "#model_name = \"google/gemma-2-9b-it\"\n",
    "model_name = \"/kaggle/input/gemma2-9b-it-cv945\"\n",
    "EPOCHS = 2\n",
    "\n",
    "DIR = f\"ver_{VER}\"\n",
    "os.makedirs(DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007004,
     "end_time": "2025-07-23T09:27:23.349095",
     "exception": false,
     "start_time": "2025-07-23T09:27:23.342091",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:33:54.558395Z",
     "iopub.status.busy": "2025-07-26T10:33:54.558153Z",
     "iopub.status.idle": "2025-07-26T10:33:59.295339Z",
     "shell.execute_reply": "2025-07-26T10:33:59.294619Z",
     "shell.execute_reply.started": "2025-07-26T10:33:54.558373Z"
    },
    "papermill": {
     "duration": 4.155998,
     "end_time": "2025-07-23T09:27:27.512349",
     "exception": false,
     "start_time": "2025-07-23T09:27:23.356351",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "train = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/train.csv')\n",
    "train.Misconception = train.Misconception.fillna('NA')\n",
    "train['target'] = train.Category+\":\"+train.Misconception\n",
    "train['label'] = le.fit_transform(train['target'])\n",
    "target_classes = le.classes_\n",
    "n_classes = len(target_classes)\n",
    "print(f\"Train shape: {train.shape} with {n_classes} target classes\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008197,
     "end_time": "2025-07-23T09:27:27.529307",
     "exception": false,
     "start_time": "2025-07-23T09:27:27.52111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Powerful Feature Engineer\n",
    "We engineer one feature which we will use when formatting the input text for our LLM. Consider using more feature engineering and/or modifying the input text to our LLM. There is a discussion about this feature [here][1]\n",
    "\n",
    "[1]: https://www.kaggle.com/competitions/map-charting-student-math-misunderstandings/discussion/589400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:33:59.296525Z",
     "iopub.status.busy": "2025-07-26T10:33:59.296259Z",
     "iopub.status.idle": "2025-07-26T10:33:59.595127Z",
     "shell.execute_reply": "2025-07-26T10:33:59.594308Z",
     "shell.execute_reply.started": "2025-07-26T10:33:59.296498Z"
    },
    "papermill": {
     "duration": 0.344932,
     "end_time": "2025-07-23T09:27:27.881839",
     "exception": false,
     "start_time": "2025-07-23T09:27:27.536907",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "idx = train.apply(lambda row: row.Category.split('_')[0],axis=1)=='True'\n",
    "correct = train.loc[idx].copy()\n",
    "correct['c'] = correct.groupby(['QuestionId','MC_Answer']).MC_Answer.transform('count')\n",
    "correct = correct.sort_values('c',ascending=False)\n",
    "correct = correct.drop_duplicates(['QuestionId'])\n",
    "correct = correct[['QuestionId','MC_Answer']]\n",
    "correct['is_correct'] = 1\n",
    "\n",
    "train = train.merge(correct, on=['QuestionId','MC_Answer'], how='left')\n",
    "train.is_correct = train.is_correct.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00784,
     "end_time": "2025-07-23T09:27:27.897826",
     "exception": false,
     "start_time": "2025-07-23T09:27:27.889986",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Question EDA\n",
    "The train.csv has 15 multiple choice math questions. Below we display each of the questions and the 4 MC choices. The choices are sorted from (A) most popular selected to (D) least popular selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-07-26T10:33:59.596264Z",
     "iopub.status.busy": "2025-07-26T10:33:59.596009Z",
     "iopub.status.idle": "2025-07-26T10:33:59.672407Z",
     "shell.execute_reply": "2025-07-26T10:33:59.671877Z",
     "shell.execute_reply.started": "2025-07-26T10:33:59.596236Z"
    },
    "papermill": {
     "duration": 0.090994,
     "end_time": "2025-07-23T09:27:27.99725",
     "exception": false,
     "start_time": "2025-07-23T09:27:27.906256",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "# GET ANSWER CHOICES\n",
    "tmp = train.groupby(['QuestionId','MC_Answer']).size().reset_index(name='count')\n",
    "tmp['rank'] = tmp.groupby('QuestionId')['count'].rank(method='dense', ascending=False).astype(int) - 1\n",
    "tmp = tmp.drop('count',axis=1)\n",
    "tmp = tmp.sort_values(['QuestionId','rank'])\n",
    "\n",
    "# DISPLAY QUESTION AND ANSWER CHOICES\n",
    "Q = tmp.QuestionId.unique()\n",
    "for q in Q:\n",
    "    question = train.loc[train.QuestionId==q].iloc[0].QuestionText\n",
    "    choices = tmp.loc[tmp.QuestionId==q].MC_Answer.values\n",
    "    labels=\"ABCD\"\n",
    "    choice_str = \" \".join([f\"({labels[i]}) {choice}\" for i, choice in enumerate(choices)])\n",
    "    \n",
    "    print()\n",
    "    display(Latex(f\"QuestionId {q}: {question}\") )\n",
    "    display(Latex(f\"MC Answers: {choice_str}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010043,
     "end_time": "2025-07-23T09:27:28.017399",
     "exception": false,
     "start_time": "2025-07-23T09:27:28.007356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train with Transformers\n",
    "We will train our Gemma2 model using Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:33:59.673321Z",
     "iopub.status.busy": "2025-07-26T10:33:59.673071Z",
     "iopub.status.idle": "2025-07-26T10:34:13.656634Z",
     "shell.execute_reply": "2025-07-26T10:34:13.655885Z",
     "shell.execute_reply.started": "2025-07-26T10:33:59.673293Z"
    },
    "papermill": {
     "duration": 13.649999,
     "end_time": "2025-07-23T09:27:41.677173",
     "exception": false,
     "start_time": "2025-07-23T09:27:28.027174",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "MAX_LEN = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009916,
     "end_time": "2025-07-23T09:27:41.697601",
     "exception": false,
     "start_time": "2025-07-23T09:27:41.687685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenize Train Data\n",
    "First we must tokenizer our data. Before we can tokenizer, we need to decide how to convert the multiple text columns into a single prompt. We will show our model the `QuestionText`, then the `MC_Answer` response, then use our `powerful feature engineer` to say whether this answer is `correct or incorrect`. Finally we will show our LLM the `StudentExplanation`.\n",
    "\n",
    "Consider changing the prompt below. Modifying the prompt can significantly improve our CV score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:34:13.658067Z",
     "iopub.status.busy": "2025-07-26T10:34:13.657539Z",
     "iopub.status.idle": "2025-07-26T10:34:14.00549Z",
     "shell.execute_reply": "2025-07-26T10:34:14.004862Z",
     "shell.execute_reply.started": "2025-07-26T10:34:13.65804Z"
    },
    "papermill": {
     "duration": 0.354269,
     "end_time": "2025-07-23T09:27:42.061939",
     "exception": false,
     "start_time": "2025-07-23T09:27:41.70767",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def format_input(row):\n",
    "    x = \"Yes\"\n",
    "    if not row['is_correct']:\n",
    "        x = \"No\"\n",
    "    return (\n",
    "        f\"Question: {row['QuestionText']}\\n\"\n",
    "        f\"Answer: {row['MC_Answer']}\\n\"\n",
    "        f\"Correct? {x}\\n\"\n",
    "        f\"Student Explanation: {row['StudentExplanation']}\"\n",
    "    )\n",
    "\n",
    "train['text'] = train.apply(format_input,axis=1)\n",
    "print(\"Example prompt for our LLM:\")\n",
    "print()\n",
    "print( train.text.values[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-07-26T10:34:14.008358Z",
     "iopub.status.busy": "2025-07-26T10:34:14.008064Z",
     "iopub.status.idle": "2025-07-26T10:34:19.837979Z",
     "shell.execute_reply": "2025-07-26T10:34:19.837202Z",
     "shell.execute_reply.started": "2025-07-26T10:34:14.00834Z"
    },
    "papermill": {
     "duration": 5.936509,
     "end_time": "2025-07-23T09:27:48.008824",
     "exception": false,
     "start_time": "2025-07-23T09:27:42.072315",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lengths = [len(tokenizer.encode(t, truncation=False)) for t in train[\"text\"]]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(lengths, bins=50)\n",
    "plt.title(\"Token Length Distribution\")\n",
    "plt.xlabel(\"Number of tokens\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:34:19.838957Z",
     "iopub.status.busy": "2025-07-26T10:34:19.838663Z",
     "iopub.status.idle": "2025-07-26T10:34:19.849261Z",
     "shell.execute_reply": "2025-07-26T10:34:19.848565Z",
     "shell.execute_reply.started": "2025-07-26T10:34:19.838936Z"
    },
    "papermill": {
     "duration": 0.022109,
     "end_time": "2025-07-23T09:27:48.041583",
     "exception": false,
     "start_time": "2025-07-23T09:27:48.019474",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "L = (np.array(lengths)>MAX_LEN).sum()\n",
    "print(f\"There are {L} train sample(s) with more than {MAX_LEN} tokens\")\n",
    "np.sort( lengths )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.05475,
     "end_time": "2025-07-23T09:27:48.107133",
     "exception": false,
     "start_time": "2025-07-23T09:27:48.052383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create 20% Validation Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:34:19.850498Z",
     "iopub.status.busy": "2025-07-26T10:34:19.850188Z",
     "iopub.status.idle": "2025-07-26T10:34:19.937298Z",
     "shell.execute_reply": "2025-07-26T10:34:19.936749Z",
     "shell.execute_reply.started": "2025-07-26T10:34:19.850472Z"
    },
    "papermill": {
     "duration": 0.0478,
     "end_time": "2025-07-23T09:27:48.165786",
     "exception": false,
     "start_time": "2025-07-23T09:27:48.117986",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split into train and validation sets\n",
    "train_df, val_df = train_test_split(train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "COLS = ['text','label']\n",
    "train_ds = Dataset.from_pandas(train_df[COLS])\n",
    "val_ds = Dataset.from_pandas(val_df[COLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:34:19.93825Z",
     "iopub.status.busy": "2025-07-26T10:34:19.938018Z",
     "iopub.status.idle": "2025-07-26T10:34:26.195902Z",
     "shell.execute_reply": "2025-07-26T10:34:26.195114Z",
     "shell.execute_reply.started": "2025-07-26T10:34:19.93823Z"
    },
    "papermill": {
     "duration": 1.09416,
     "end_time": "2025-07-23T09:27:49.270645",
     "exception": false,
     "start_time": "2025-07-23T09:27:48.176485",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "val_ds = val_ds.map(tokenize, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "columns = ['input_ids', 'attention_mask', 'label']\n",
    "train_ds.set_format(type='torch', columns=columns)\n",
    "val_ds.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010663,
     "end_time": "2025-07-23T09:27:49.292456",
     "exception": false,
     "start_time": "2025-07-23T09:27:49.281793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Initialize Model\n",
    "Let's initialize and train our model with HuggingFace trainer. We also define a custom metric of MAP@3 which is the competition metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:34:26.197406Z",
     "iopub.status.busy": "2025-07-26T10:34:26.196745Z",
     "iopub.status.idle": "2025-07-26T10:37:09.529735Z",
     "shell.execute_reply": "2025-07-26T10:37:09.529194Z",
     "shell.execute_reply.started": "2025-07-26T10:34:26.197382Z"
    },
    "papermill": {
     "duration": 151.503296,
     "end_time": "2025-07-23T09:30:20.806291",
     "exception": false,
     "start_time": "2025-07-23T09:27:49.302995",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"/kaggle/input/gemma2-9b-it-bf16\",\n",
    "    num_labels=n_classes,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PEFT Adapter and Infer\n",
    "We trained this model with a LORA adapter. So now during inference we load the saved LORA adapter to wrap the pretrained `Gemma2-9B-it` base model. (To learn how to train with LORA/QLORA, see previous competition notebook [here][1])\n",
    "\n",
    "[1]: https://www.kaggle.com/code/cdeotte/16th-place-train-1-of-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:37:09.531566Z",
     "iopub.status.busy": "2025-07-26T10:37:09.530551Z",
     "iopub.status.idle": "2025-07-26T10:37:11.08781Z",
     "shell.execute_reply": "2025-07-26T10:37:11.087056Z",
     "shell.execute_reply.started": "2025-07-26T10:37:09.531543Z"
    },
    "papermill": {
     "duration": 1.472154,
     "end_time": "2025-07-23T09:30:22.290055",
     "exception": false,
     "start_time": "2025-07-23T09:30:20.817901",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "model = PeftModel.from_pretrained(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:37:11.089158Z",
     "iopub.status.busy": "2025-07-26T10:37:11.088904Z",
     "iopub.status.idle": "2025-07-26T10:37:11.120918Z",
     "shell.execute_reply": "2025-07-26T10:37:11.12036Z",
     "shell.execute_reply.started": "2025-07-26T10:37:11.089132Z"
    },
    "papermill": {
     "duration": 0.044343,
     "end_time": "2025-07-23T09:30:22.346342",
     "exception": false,
     "start_time": "2025-07-23T09:30:22.301999",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = f\"./{DIR}\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\", #no for no saving \n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model=\"map@3\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    bf16=False, # TRAIN WITH BF16 IF LOCAL GPU IS NEWER GPU          \n",
    "    fp16=True, # INFER WITH FP16 BECAUSE KAGGLE IS T4 GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:37:11.121788Z",
     "iopub.status.busy": "2025-07-26T10:37:11.121569Z",
     "iopub.status.idle": "2025-07-26T10:37:11.126669Z",
     "shell.execute_reply": "2025-07-26T10:37:11.126059Z",
     "shell.execute_reply.started": "2025-07-26T10:37:11.121772Z"
    },
    "papermill": {
     "duration": 0.017012,
     "end_time": "2025-07-23T09:30:22.37461",
     "exception": false,
     "start_time": "2025-07-23T09:30:22.357598",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CUSTOM MAP@3 METRIC\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def compute_map3(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "    \n",
    "    top3 = np.argsort(-probs, axis=1)[:, :3]  # Top 3 predictions\n",
    "    match = (top3 == labels[:, None])\n",
    "\n",
    "    # Compute MAP@3 manually\n",
    "    map3 = 0\n",
    "    for i in range(len(labels)):\n",
    "        if match[i, 0]:\n",
    "            map3 += 1.0\n",
    "        elif match[i, 1]:\n",
    "            map3 += 1.0 / 2\n",
    "        elif match[i, 2]:\n",
    "            map3 += 1.0 / 3\n",
    "    return {\"map@3\": map3 / len(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:37:11.127884Z",
     "iopub.status.busy": "2025-07-26T10:37:11.127422Z",
     "iopub.status.idle": "2025-07-26T10:37:11.166931Z",
     "shell.execute_reply": "2025-07-26T10:37:11.166234Z",
     "shell.execute_reply.started": "2025-07-26T10:37:11.12784Z"
    },
    "papermill": {
     "duration": 0.035103,
     "end_time": "2025-07-23T09:30:22.420323",
     "exception": false,
     "start_time": "2025-07-23T09:30:22.38522",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_map3,\n",
    ")\n",
    "\n",
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01256,
     "end_time": "2025-07-23T09:35:20.702417",
     "exception": false,
     "start_time": "2025-07-23T09:35:20.689857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save Model\n",
    "This is how to save the files we need to upload to a Kaggle dataset for inference. If we train with LORA/QLORA adapter then this save command efficiently only saves the LORA adapter. (i.e. the same LORA adapter that this inference notebook is using)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:37:11.167857Z",
     "iopub.status.busy": "2025-07-26T10:37:11.167599Z",
     "iopub.status.idle": "2025-07-26T10:37:11.170709Z",
     "shell.execute_reply": "2025-07-26T10:37:11.170173Z",
     "shell.execute_reply.started": "2025-07-26T10:37:11.167813Z"
    },
    "papermill": {
     "duration": 0.015849,
     "end_time": "2025-07-23T09:35:20.729815",
     "exception": false,
     "start_time": "2025-07-23T09:35:20.713966",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#trainer.save_model(f\"ver_{VER}\")      \n",
    "#tokenizer.save_pretrained(f\"ver_{VER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010829,
     "end_time": "2025-07-23T09:35:20.751644",
     "exception": false,
     "start_time": "2025-07-23T09:35:20.740815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load and Predict Test \n",
    "We load test data, then engineer our powerful feature, then create prompt, then tokenize. Finally we infer test and generate probabilities for all 65 multi-classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:37:11.171548Z",
     "iopub.status.busy": "2025-07-26T10:37:11.171342Z",
     "iopub.status.idle": "2025-07-26T10:37:11.199324Z",
     "shell.execute_reply": "2025-07-26T10:37:11.198611Z",
     "shell.execute_reply.started": "2025-07-26T10:37:11.171533Z"
    },
    "papermill": {
     "duration": 0.026842,
     "end_time": "2025-07-23T09:35:20.789513",
     "exception": false,
     "start_time": "2025-07-23T09:35:20.762671",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/test.csv')\n",
    "print( test.shape )\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:37:11.200552Z",
     "iopub.status.busy": "2025-07-26T10:37:11.200074Z",
     "iopub.status.idle": "2025-07-26T10:37:11.212433Z",
     "shell.execute_reply": "2025-07-26T10:37:11.211924Z",
     "shell.execute_reply.started": "2025-07-26T10:37:11.200529Z"
    },
    "papermill": {
     "duration": 0.025159,
     "end_time": "2025-07-23T09:35:20.826363",
     "exception": false,
     "start_time": "2025-07-23T09:35:20.801204",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test = test.merge(correct, on=['QuestionId','MC_Answer'], how='left')\n",
    "test.is_correct = test.is_correct.fillna(0)\n",
    "\n",
    "test['text'] = test.apply(format_input,axis=1)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:37:11.213545Z",
     "iopub.status.busy": "2025-07-26T10:37:11.213268Z",
     "iopub.status.idle": "2025-07-26T10:37:14.129486Z",
     "shell.execute_reply": "2025-07-26T10:37:14.128945Z",
     "shell.execute_reply.started": "2025-07-26T10:37:11.21352Z"
    },
    "papermill": {
     "duration": 1.577298,
     "end_time": "2025-07-23T09:35:22.414949",
     "exception": false,
     "start_time": "2025-07-23T09:35:20.837651",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds_test = Dataset.from_pandas(test[['text']])\n",
    "ds_test = ds_test.map(tokenize, batched=True)\n",
    "\n",
    "predictions = trainer.predict(ds_test)\n",
    "probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011841,
     "end_time": "2025-07-23T09:35:22.439646",
     "exception": false,
     "start_time": "2025-07-23T09:35:22.427805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Submission CSV\n",
    "We create submission.csv by converting our top3 test preds into their class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:37:14.13052Z",
     "iopub.status.busy": "2025-07-26T10:37:14.130242Z",
     "iopub.status.idle": "2025-07-26T10:37:14.146251Z",
     "shell.execute_reply": "2025-07-26T10:37:14.145672Z",
     "shell.execute_reply.started": "2025-07-26T10:37:14.130491Z"
    },
    "papermill": {
     "duration": 0.027873,
     "end_time": "2025-07-23T09:35:22.479215",
     "exception": false,
     "start_time": "2025-07-23T09:35:22.451342",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get top 3 predicted class indices\n",
    "top3 = np.argsort(-probs, axis=1)[:, :]   # shape: [num_samples, 3]\n",
    "\n",
    "# Decode numeric class indices to original string labels\n",
    "flat_top3 = top3.flatten()\n",
    "decoded_labels = le.inverse_transform(flat_top3)\n",
    "top3_labels = decoded_labels.reshape(top3.shape)\n",
    "\n",
    "# Join 3 labels per row with space\n",
    "joined_preds = [\"|\".join(row) for row in top3_labels]\n",
    "\n",
    "# Save submission\n",
    "sub = pd.DataFrame({\n",
    "    \"row_id\": test.row_id.values,\n",
    "    \"Category:Misconception\": joined_preds\n",
    "})\n",
    "sub.to_csv(\"submission_gemma.csv\", index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:37:14.147168Z",
     "iopub.status.busy": "2025-07-26T10:37:14.146889Z",
     "iopub.status.idle": "2025-07-26T10:37:14.160509Z",
     "shell.execute_reply": "2025-07-26T10:37:14.159759Z",
     "shell.execute_reply.started": "2025-07-26T10:37:14.147144Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sub.iloc[0]['Category:Misconception']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:37:14.163378Z",
     "iopub.status.busy": "2025-07-26T10:37:14.163187Z",
     "iopub.status.idle": "2025-07-26T10:37:14.595084Z",
     "shell.execute_reply": "2025-07-26T10:37:14.594346Z",
     "shell.execute_reply.started": "2025-07-26T10:37:14.163363Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "del top3_labels, flat_top3, decoded_labels, top3, test, ds_test\n",
    "del training_args, train_ds, val_ds, model, trainer, predictions, probs\n",
    "# Delete any other lingering references\n",
    "for obj in list(globals().keys()):\n",
    "    if isinstance(globals()[obj], torch.nn.Module) or isinstance(globals()[obj], torch.Tensor):\n",
    "        del globals()[obj]\n",
    "\n",
    "# Dọn sạch autograd\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Nếu dùng nhiều GPU, làm thêm bước này để clear hết:\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "# In ra kiểm tra\n",
    "print(\"Memory allocated:\", torch.cuda.memory_allocated())\n",
    "print(\"Memory reserved:\", torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:37:14.595928Z",
     "iopub.status.busy": "2025-07-26T10:37:14.595703Z",
     "iopub.status.idle": "2025-07-26T10:37:15.026116Z",
     "shell.execute_reply": "2025-07-26T10:37:15.02546Z",
     "shell.execute_reply.started": "2025-07-26T10:37:14.595911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Delete any other lingering references\n",
    "for obj in list(globals().keys()):\n",
    "    if isinstance(globals()[obj], torch.nn.Module) or isinstance(globals()[obj], torch.Tensor):\n",
    "        del globals()[obj]\n",
    "\n",
    "# Dọn sạch autograd\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Nếu dùng nhiều GPU, làm thêm bước này để clear hết:\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "# In ra kiểm tra\n",
    "print(\"Memory allocated:\", torch.cuda.memory_allocated())\n",
    "print(\"Memory reserved:\", torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:37:15.027081Z",
     "iopub.status.busy": "2025-07-26T10:37:15.026811Z",
     "iopub.status.idle": "2025-07-26T10:37:15.375286Z",
     "shell.execute_reply": "2025-07-26T10:37:15.374559Z",
     "shell.execute_reply.started": "2025-07-26T10:37:15.027055Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Delete any other lingering references\n",
    "for obj in list(globals().keys()):\n",
    "    if isinstance(globals()[obj], torch.nn.Module) or isinstance(globals()[obj], torch.Tensor):\n",
    "        del globals()[obj]\n",
    "\n",
    "# Dọn sạch autograd\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Nếu dùng nhiều GPU, làm thêm bước này để clear hết:\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "# In ra kiểm tra\n",
    "print(\"Memory allocated:\", torch.cuda.memory_allocated())\n",
    "print(\"Memory reserved:\", torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:37:15.376258Z",
     "iopub.status.busy": "2025-07-26T10:37:15.376053Z",
     "iopub.status.idle": "2025-07-26T10:37:15.746474Z",
     "shell.execute_reply": "2025-07-26T10:37:15.745744Z",
     "shell.execute_reply.started": "2025-07-26T10:37:15.376244Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Delete any other lingering references\n",
    "for obj in list(globals().keys()):\n",
    "    if isinstance(globals()[obj], torch.nn.Module) or isinstance(globals()[obj], torch.Tensor):\n",
    "        del globals()[obj]\n",
    "\n",
    "# Dọn sạch autograd\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Nếu dùng nhiều GPU, làm thêm bước này để clear hết:\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "# In ra kiểm tra\n",
    "print(\"Memory allocated:\", torch.cuda.memory_allocated())\n",
    "print(\"Memory reserved:\", torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Ettin-Encoder-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:38:59.331177Z",
     "iopub.status.busy": "2025-07-26T10:38:59.330457Z",
     "iopub.status.idle": "2025-07-26T10:38:59.335167Z",
     "shell.execute_reply": "2025-07-26T10:38:59.334348Z",
     "shell.execute_reply.started": "2025-07-26T10:38:59.331151Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "VER=1\n",
    "#model_name = \"jhu-clsp/ettin-encoder-1b\"\n",
    "model_name = \"/kaggle/input/ettin-encoder-1b-cv943\"\n",
    "EPOCHS = 3\n",
    "\n",
    "DIR = f\"ver_{VER}\"\n",
    "os.makedirs(DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:39:01.131324Z",
     "iopub.status.busy": "2025-07-26T10:39:01.131064Z",
     "iopub.status.idle": "2025-07-26T10:39:01.273414Z",
     "shell.execute_reply": "2025-07-26T10:39:01.272721Z",
     "shell.execute_reply.started": "2025-07-26T10:39:01.131305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "train = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/train.csv')\n",
    "train.Misconception = train.Misconception.fillna('NA')\n",
    "train['target'] = train.Category+\":\"+train.Misconception\n",
    "train['label'] = le.fit_transform(train['target'])\n",
    "n_classes = len(le.classes_)\n",
    "print(f\"Train shape: {train.shape} with {n_classes} target classes\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:39:03.823487Z",
     "iopub.status.busy": "2025-07-26T10:39:03.823251Z",
     "iopub.status.idle": "2025-07-26T10:39:04.09119Z",
     "shell.execute_reply": "2025-07-26T10:39:04.090603Z",
     "shell.execute_reply.started": "2025-07-26T10:39:03.823471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "idx = train.apply(lambda row: row.Category.split('_')[0],axis=1)=='True'\n",
    "correct = train.loc[idx].copy()\n",
    "correct['c'] = correct.groupby(['QuestionId','MC_Answer']).MC_Answer.transform('count')\n",
    "correct = correct.sort_values('c',ascending=False)\n",
    "correct = correct.drop_duplicates(['QuestionId'])\n",
    "correct = correct[['QuestionId','MC_Answer']]\n",
    "correct['is_correct'] = 1\n",
    "\n",
    "train = train.merge(correct, on=['QuestionId','MC_Answer'], how='left')\n",
    "train.is_correct = train.is_correct.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:39:05.394961Z",
     "iopub.status.busy": "2025-07-26T10:39:05.394262Z",
     "iopub.status.idle": "2025-07-26T10:39:05.465745Z",
     "shell.execute_reply": "2025-07-26T10:39:05.465198Z",
     "shell.execute_reply.started": "2025-07-26T10:39:05.394935Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "# GET ANSWER CHOICES\n",
    "tmp = train.groupby(['QuestionId','MC_Answer']).size().reset_index(name='count')\n",
    "tmp['rank'] = tmp.groupby('QuestionId')['count'].rank(method='dense', ascending=False).astype(int) - 1\n",
    "tmp = tmp.drop('count',axis=1)\n",
    "tmp = tmp.sort_values(['QuestionId','rank'])\n",
    "\n",
    "# DISPLAY QUESTION AND ANSWER CHOICES\n",
    "Q = tmp.QuestionId.unique()\n",
    "for q in Q:\n",
    "    question = train.loc[train.QuestionId==q].iloc[0].QuestionText\n",
    "    choices = tmp.loc[tmp.QuestionId==q].MC_Answer.values\n",
    "    labels=\"ABCD\"\n",
    "    choice_str = \" \".join([f\"({labels[i]}) {choice}\" for i, choice in enumerate(choices)])\n",
    "    \n",
    "    print()\n",
    "    display(Latex(f\"QuestionId {q}: {question}\") )\n",
    "    display(Latex(f\"MC Answers: {choice_str}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:39:09.271509Z",
     "iopub.status.busy": "2025-07-26T10:39:09.271272Z",
     "iopub.status.idle": "2025-07-26T10:39:09.522435Z",
     "shell.execute_reply": "2025-07-26T10:39:09.521625Z",
     "shell.execute_reply.started": "2025-07-26T10:39:09.271494Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "MAX_LEN = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:39:10.821142Z",
     "iopub.status.busy": "2025-07-26T10:39:10.820858Z",
     "iopub.status.idle": "2025-07-26T10:39:11.169682Z",
     "shell.execute_reply": "2025-07-26T10:39:11.16896Z",
     "shell.execute_reply.started": "2025-07-26T10:39:10.821121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def format_input(row):\n",
    "    x = \"Yes\"\n",
    "    if not row['is_correct']:\n",
    "        x = \"No\"\n",
    "    return (\n",
    "        f\"Question: {row['QuestionText']}\\n\"\n",
    "        f\"Answer: {row['MC_Answer']}\\n\"\n",
    "        f\"Correct? {x}\\n\"\n",
    "        f\"Student Explanation: {row['StudentExplanation']}\"\n",
    "    )\n",
    "\n",
    "train['text'] = train.apply(format_input,axis=1)\n",
    "print(\"Example prompt for our LLM:\")\n",
    "print()\n",
    "print( train.text.values[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:39:13.043422Z",
     "iopub.status.busy": "2025-07-26T10:39:13.042633Z",
     "iopub.status.idle": "2025-07-26T10:39:20.741774Z",
     "shell.execute_reply": "2025-07-26T10:39:20.741033Z",
     "shell.execute_reply.started": "2025-07-26T10:39:13.043395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lengths = [len(tokenizer.encode(t, truncation=False)) for t in train[\"text\"]]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(lengths, bins=50)\n",
    "plt.title(\"Token Length Distribution\")\n",
    "plt.xlabel(\"Number of tokens\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:39:20.743562Z",
     "iopub.status.busy": "2025-07-26T10:39:20.74314Z",
     "iopub.status.idle": "2025-07-26T10:39:20.753584Z",
     "shell.execute_reply": "2025-07-26T10:39:20.752887Z",
     "shell.execute_reply.started": "2025-07-26T10:39:20.743542Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "L = (np.array(lengths)>MAX_LEN).sum()\n",
    "print(f\"There are {L} train sample(s) with more than {MAX_LEN} tokens\")\n",
    "np.sort( lengths )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:39:20.754791Z",
     "iopub.status.busy": "2025-07-26T10:39:20.754509Z",
     "iopub.status.idle": "2025-07-26T10:39:20.824527Z",
     "shell.execute_reply": "2025-07-26T10:39:20.823751Z",
     "shell.execute_reply.started": "2025-07-26T10:39:20.754762Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split into train and validation sets\n",
    "train_df, val_df = train_test_split(train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "COLS = ['text','label']\n",
    "train_ds = Dataset.from_pandas(train_df[COLS])\n",
    "val_ds = Dataset.from_pandas(val_df[COLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:39:20.826243Z",
     "iopub.status.busy": "2025-07-26T10:39:20.825983Z",
     "iopub.status.idle": "2025-07-26T10:39:27.103843Z",
     "shell.execute_reply": "2025-07-26T10:39:27.103132Z",
     "shell.execute_reply.started": "2025-07-26T10:39:20.826218Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "val_ds = val_ds.map(tokenize, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "columns = ['input_ids', 'attention_mask', 'label']\n",
    "train_ds.set_format(type='torch', columns=columns)\n",
    "val_ds.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:39:27.1049Z",
     "iopub.status.busy": "2025-07-26T10:39:27.104624Z",
     "iopub.status.idle": "2025-07-26T10:39:29.407618Z",
     "shell.execute_reply": "2025-07-26T10:39:29.406765Z",
     "shell.execute_reply.started": "2025-07-26T10:39:27.104876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=n_classes,\n",
    "    reference_compile=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:39:31.78921Z",
     "iopub.status.busy": "2025-07-26T10:39:31.788575Z",
     "iopub.status.idle": "2025-07-26T10:39:31.825039Z",
     "shell.execute_reply": "2025-07-26T10:39:31.824343Z",
     "shell.execute_reply.started": "2025-07-26T10:39:31.789186Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = f\"./{DIR}\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\", #no for no saving \n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=16*2,\n",
    "    per_device_eval_batch_size=32*2,\n",
    "    learning_rate=5e-5,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model=\"map@3\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    bf16=False, # TRAIN WITH BF16 IF LOCAL GPU IS NEWER GPU          \n",
    "    fp16=True, # INFER WITH FP16 BECAUSE KAGGLE IS T4 GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:39:33.912552Z",
     "iopub.status.busy": "2025-07-26T10:39:33.912077Z",
     "iopub.status.idle": "2025-07-26T10:39:33.917849Z",
     "shell.execute_reply": "2025-07-26T10:39:33.917086Z",
     "shell.execute_reply.started": "2025-07-26T10:39:33.912532Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CUSTOM MAP@3 METRIC\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def compute_map3(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "    \n",
    "    top3 = np.argsort(-probs, axis=1)[:, :3]  # Top 3 predictions\n",
    "    match = (top3 == labels[:, None])\n",
    "\n",
    "    # Compute MAP@3 manually\n",
    "    map3 = 0\n",
    "    for i in range(len(labels)):\n",
    "        if match[i, 0]:\n",
    "            map3 += 1.0\n",
    "        elif match[i, 1]:\n",
    "            map3 += 1.0 / 2\n",
    "        elif match[i, 2]:\n",
    "            map3 += 1.0 / 3\n",
    "    return {\"map@3\": map3 / len(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:39:35.708733Z",
     "iopub.status.busy": "2025-07-26T10:39:35.708456Z",
     "iopub.status.idle": "2025-07-26T10:40:07.16025Z",
     "shell.execute_reply": "2025-07-26T10:40:07.159447Z",
     "shell.execute_reply.started": "2025-07-26T10:39:35.708714Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_map3,\n",
    ")\n",
    "\n",
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:40:07.161689Z",
     "iopub.status.busy": "2025-07-26T10:40:07.161452Z",
     "iopub.status.idle": "2025-07-26T10:40:07.172802Z",
     "shell.execute_reply": "2025-07-26T10:40:07.172054Z",
     "shell.execute_reply.started": "2025-07-26T10:40:07.161673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/test.csv')\n",
    "print( test.shape )\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:40:07.17413Z",
     "iopub.status.busy": "2025-07-26T10:40:07.17356Z",
     "iopub.status.idle": "2025-07-26T10:40:07.192798Z",
     "shell.execute_reply": "2025-07-26T10:40:07.192208Z",
     "shell.execute_reply.started": "2025-07-26T10:40:07.174112Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test = test.merge(correct, on=['QuestionId','MC_Answer'], how='left')\n",
    "test.is_correct = test.is_correct.fillna(0)\n",
    "\n",
    "test['text'] = test.apply(format_input,axis=1)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:40:07.1943Z",
     "iopub.status.busy": "2025-07-26T10:40:07.194082Z",
     "iopub.status.idle": "2025-07-26T10:40:08.791469Z",
     "shell.execute_reply": "2025-07-26T10:40:08.790771Z",
     "shell.execute_reply.started": "2025-07-26T10:40:07.194285Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds_test = Dataset.from_pandas(test[['text']])\n",
    "ds_test = ds_test.map(tokenize, batched=True)\n",
    "\n",
    "predictions = trainer.predict(ds_test)\n",
    "probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:40:08.792492Z",
     "iopub.status.busy": "2025-07-26T10:40:08.792246Z",
     "iopub.status.idle": "2025-07-26T10:40:08.803052Z",
     "shell.execute_reply": "2025-07-26T10:40:08.80238Z",
     "shell.execute_reply.started": "2025-07-26T10:40:08.792469Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get top 3 predicted class indices\n",
    "top3 = np.argsort(-probs, axis=1)[:, :]   # shape: [num_samples, 3]\n",
    "\n",
    "# Decode numeric class indices to original string labels\n",
    "flat_top3 = top3.flatten()\n",
    "decoded_labels = le.inverse_transform(flat_top3)\n",
    "top3_labels = decoded_labels.reshape(top3.shape)\n",
    "\n",
    "# Join 3 labels per row with space\n",
    "joined_preds = [\"|\".join(row) for row in top3_labels]\n",
    "\n",
    "# Save submission\n",
    "sub = pd.DataFrame({\n",
    "    \"row_id\": test.row_id.values,\n",
    "    \"Category:Misconception\": joined_preds\n",
    "})\n",
    "sub.to_csv(\"submission_ettin.csv\", index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:40:26.935785Z",
     "iopub.status.busy": "2025-07-26T10:40:26.935549Z",
     "iopub.status.idle": "2025-07-26T10:40:26.940879Z",
     "shell.execute_reply": "2025-07-26T10:40:26.940281Z",
     "shell.execute_reply.started": "2025-07-26T10:40:26.935769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sub.iloc[0]['Category:Misconception']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:44:19.421971Z",
     "iopub.status.busy": "2025-07-26T10:44:19.421659Z",
     "iopub.status.idle": "2025-07-26T10:44:20.067077Z",
     "shell.execute_reply": "2025-07-26T10:44:20.066239Z",
     "shell.execute_reply.started": "2025-07-26T10:44:19.421951Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "del top3_labels, flat_top3, decoded_labels, top3, test, ds_test\n",
    "del training_args, train_ds, val_ds, model, trainer, predictions, probs\n",
    "# Delete any other lingering references\n",
    "for obj in list(globals().keys()):\n",
    "    if isinstance(globals()[obj], torch.nn.Module) or isinstance(globals()[obj], torch.Tensor):\n",
    "        del globals()[obj]\n",
    "\n",
    "# Dọn sạch autograd\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Nếu dùng nhiều GPU, làm thêm bước này để clear hết:\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "# In ra kiểm tra\n",
    "print(\"Memory allocated:\", torch.cuda.memory_allocated())\n",
    "print(\"Memory reserved:\", torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:44:21.712754Z",
     "iopub.status.busy": "2025-07-26T10:44:21.712093Z",
     "iopub.status.idle": "2025-07-26T10:44:22.109195Z",
     "shell.execute_reply": "2025-07-26T10:44:22.108441Z",
     "shell.execute_reply.started": "2025-07-26T10:44:21.712729Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for obj in list(globals().keys()):\n",
    "    if isinstance(globals()[obj], torch.nn.Module) or isinstance(globals()[obj], torch.Tensor):\n",
    "        del globals()[obj]\n",
    "\n",
    "# Dọn sạch autograd\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Nếu dùng nhiều GPU, làm thêm bước này để clear hết:\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "# In ra kiểm tra\n",
    "print(\"Memory allocated:\", torch.cuda.memory_allocated())\n",
    "print(\"Memory reserved:\", torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:44:23.462889Z",
     "iopub.status.busy": "2025-07-26T10:44:23.462594Z",
     "iopub.status.idle": "2025-07-26T10:44:23.856959Z",
     "shell.execute_reply": "2025-07-26T10:44:23.856285Z",
     "shell.execute_reply.started": "2025-07-26T10:44:23.46287Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for obj in list(globals().keys()):\n",
    "    if isinstance(globals()[obj], torch.nn.Module) or isinstance(globals()[obj], torch.Tensor):\n",
    "        del globals()[obj]\n",
    "\n",
    "# Dọn sạch autograd\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Nếu dùng nhiều GPU, làm thêm bước này để clear hết:\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "# In ra kiểm tra\n",
    "print(\"Memory allocated:\", torch.cuda.memory_allocated())\n",
    "print(\"Memory reserved:\", torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:44:25.208527Z",
     "iopub.status.busy": "2025-07-26T10:44:25.208262Z",
     "iopub.status.idle": "2025-07-26T10:44:25.607312Z",
     "shell.execute_reply": "2025-07-26T10:44:25.606747Z",
     "shell.execute_reply.started": "2025-07-26T10:44:25.208508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for obj in list(globals().keys()):\n",
    "    if isinstance(globals()[obj], torch.nn.Module) or isinstance(globals()[obj], torch.Tensor):\n",
    "        del globals()[obj]\n",
    "\n",
    "# Dọn sạch autograd\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Nếu dùng nhiều GPU, làm thêm bước này để clear hết:\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "# In ra kiểm tra\n",
    "print(\"Memory allocated:\", torch.cuda.memory_allocated())\n",
    "print(\"Memory reserved:\", torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MODERN BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:48:28.332052Z",
     "iopub.status.busy": "2025-07-26T10:48:28.331744Z",
     "iopub.status.idle": "2025-07-26T10:48:28.336352Z",
     "shell.execute_reply": "2025-07-26T10:48:28.335784Z",
     "shell.execute_reply.started": "2025-07-26T10:48:28.332032Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "VER=1\n",
    "#model_name = \"answerdotai/ModernBERT-large\"\n",
    "model_name = \"/kaggle/input/modernbert-large-cv938\"\n",
    "EPOCHS = 3\n",
    "\n",
    "DIR = f\"ver_{VER}\"\n",
    "os.makedirs(DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:48:30.034299Z",
     "iopub.status.busy": "2025-07-26T10:48:30.034034Z",
     "iopub.status.idle": "2025-07-26T10:48:30.164015Z",
     "shell.execute_reply": "2025-07-26T10:48:30.163343Z",
     "shell.execute_reply.started": "2025-07-26T10:48:30.03428Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "train = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/train.csv')\n",
    "train.Misconception = train.Misconception.fillna('NA')\n",
    "train['target'] = train.Category+\":\"+train.Misconception\n",
    "train['label'] = le.fit_transform(train['target'])\n",
    "n_classes = len(le.classes_)\n",
    "print(f\"Train shape: {train.shape} with {n_classes} target classes\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:48:32.649738Z",
     "iopub.status.busy": "2025-07-26T10:48:32.649444Z",
     "iopub.status.idle": "2025-07-26T10:48:32.915858Z",
     "shell.execute_reply": "2025-07-26T10:48:32.915249Z",
     "shell.execute_reply.started": "2025-07-26T10:48:32.649715Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "idx = train.apply(lambda row: row.Category.split('_')[0],axis=1)=='True'\n",
    "correct = train.loc[idx].copy()\n",
    "correct['c'] = correct.groupby(['QuestionId','MC_Answer']).MC_Answer.transform('count')\n",
    "correct = correct.sort_values('c',ascending=False)\n",
    "correct = correct.drop_duplicates(['QuestionId'])\n",
    "correct = correct[['QuestionId','MC_Answer']]\n",
    "correct['is_correct'] = 1\n",
    "\n",
    "train = train.merge(correct, on=['QuestionId','MC_Answer'], how='left')\n",
    "train.is_correct = train.is_correct.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:48:35.117144Z",
     "iopub.status.busy": "2025-07-26T10:48:35.116902Z",
     "iopub.status.idle": "2025-07-26T10:48:35.188804Z",
     "shell.execute_reply": "2025-07-26T10:48:35.188256Z",
     "shell.execute_reply.started": "2025-07-26T10:48:35.117128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "# GET ANSWER CHOICES\n",
    "tmp = train.groupby(['QuestionId','MC_Answer']).size().reset_index(name='count')\n",
    "tmp['rank'] = tmp.groupby('QuestionId')['count'].rank(method='dense', ascending=False).astype(int) - 1\n",
    "tmp = tmp.drop('count',axis=1)\n",
    "tmp = tmp.sort_values(['QuestionId','rank'])\n",
    "\n",
    "# DISPLAY QUESTION AND ANSWER CHOICES\n",
    "Q = tmp.QuestionId.unique()\n",
    "for q in Q:\n",
    "    question = train.loc[train.QuestionId==q].iloc[0].QuestionText\n",
    "    choices = tmp.loc[tmp.QuestionId==q].MC_Answer.values\n",
    "    labels=\"ABCD\"\n",
    "    choice_str = \" \".join([f\"({labels[i]}) {choice}\" for i, choice in enumerate(choices)])\n",
    "    \n",
    "    print()\n",
    "    display(Latex(f\"QuestionId {q}: {question}\") )\n",
    "    display(Latex(f\"MC Answers: {choice_str}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:48:42.777887Z",
     "iopub.status.busy": "2025-07-26T10:48:42.777589Z",
     "iopub.status.idle": "2025-07-26T10:48:43.005237Z",
     "shell.execute_reply": "2025-07-26T10:48:43.00444Z",
     "shell.execute_reply.started": "2025-07-26T10:48:42.777866Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "MAX_LEN = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:48:44.400722Z",
     "iopub.status.busy": "2025-07-26T10:48:44.400153Z",
     "iopub.status.idle": "2025-07-26T10:48:44.742914Z",
     "shell.execute_reply": "2025-07-26T10:48:44.742319Z",
     "shell.execute_reply.started": "2025-07-26T10:48:44.4007Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def format_input(row):\n",
    "    x = \"This answer is correct.\"\n",
    "    if not row['is_correct']:\n",
    "        x = \"This is answer is incorrect.\"\n",
    "    return (\n",
    "        f\"Question: {row['QuestionText']}\\n\"\n",
    "        f\"Answer: {row['MC_Answer']}\\n\"\n",
    "        f\"{x}\\n\"\n",
    "        f\"Student Explanation: {row['StudentExplanation']}\"\n",
    "    )\n",
    "\n",
    "train['text'] = train.apply(format_input,axis=1)\n",
    "print(\"Example prompt for our LLM:\")\n",
    "print()\n",
    "print( train.text.values[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:48:47.162705Z",
     "iopub.status.busy": "2025-07-26T10:48:47.162224Z",
     "iopub.status.idle": "2025-07-26T10:48:55.405397Z",
     "shell.execute_reply": "2025-07-26T10:48:55.404561Z",
     "shell.execute_reply.started": "2025-07-26T10:48:47.162681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lengths = [len(tokenizer.encode(t, truncation=False)) for t in train[\"text\"]]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(lengths, bins=50)\n",
    "plt.title(\"Token Length Distribution\")\n",
    "plt.xlabel(\"Number of tokens\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:48:55.406724Z",
     "iopub.status.busy": "2025-07-26T10:48:55.406527Z",
     "iopub.status.idle": "2025-07-26T10:48:55.416468Z",
     "shell.execute_reply": "2025-07-26T10:48:55.415751Z",
     "shell.execute_reply.started": "2025-07-26T10:48:55.406709Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "L = (np.array(lengths)>MAX_LEN).sum()\n",
    "print(f\"There are {L} train sample(s) with more than {MAX_LEN} tokens\")\n",
    "np.sort( lengths )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:48:55.41745Z",
     "iopub.status.busy": "2025-07-26T10:48:55.417218Z",
     "iopub.status.idle": "2025-07-26T10:48:55.49818Z",
     "shell.execute_reply": "2025-07-26T10:48:55.497656Z",
     "shell.execute_reply.started": "2025-07-26T10:48:55.417434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split into train and validation sets\n",
    "train_df, val_df = train_test_split(train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "COLS = ['text','label']\n",
    "train_ds = Dataset.from_pandas(train_df[COLS])\n",
    "val_ds = Dataset.from_pandas(val_df[COLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:48:55.499751Z",
     "iopub.status.busy": "2025-07-26T10:48:55.49952Z",
     "iopub.status.idle": "2025-07-26T10:49:01.946574Z",
     "shell.execute_reply": "2025-07-26T10:49:01.945785Z",
     "shell.execute_reply.started": "2025-07-26T10:48:55.499735Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "val_ds = val_ds.map(tokenize, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "columns = ['input_ids', 'attention_mask', 'label']\n",
    "train_ds.set_format(type='torch', columns=columns)\n",
    "val_ds.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:49:01.948091Z",
     "iopub.status.busy": "2025-07-26T10:49:01.947715Z",
     "iopub.status.idle": "2025-07-26T10:49:02.656516Z",
     "shell.execute_reply": "2025-07-26T10:49:02.65597Z",
     "shell.execute_reply.started": "2025-07-26T10:49:01.948047Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=n_classes,\n",
    "    reference_compile=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:49:02.65776Z",
     "iopub.status.busy": "2025-07-26T10:49:02.657515Z",
     "iopub.status.idle": "2025-07-26T10:49:02.72295Z",
     "shell.execute_reply": "2025-07-26T10:49:02.722163Z",
     "shell.execute_reply.started": "2025-07-26T10:49:02.657735Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = f\"./{DIR}\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\", #no for no saving \n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=16*2,\n",
    "    per_device_eval_batch_size=32*2,\n",
    "    learning_rate=5e-5,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model=\"map@3\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    bf16=False, # TRAIN WITH BF16 IF LOCAL GPU IS NEWER GPU          \n",
    "    fp16=True, # INFER WITH FP16 BECAUSE KAGGLE IS T4 GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:49:05.031902Z",
     "iopub.status.busy": "2025-07-26T10:49:05.031403Z",
     "iopub.status.idle": "2025-07-26T10:49:05.03711Z",
     "shell.execute_reply": "2025-07-26T10:49:05.036379Z",
     "shell.execute_reply.started": "2025-07-26T10:49:05.031876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CUSTOM MAP@3 METRIC\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def compute_map3(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "    \n",
    "    top3 = np.argsort(-probs, axis=1)[:, :3]  # Top 3 predictions\n",
    "    match = (top3 == labels[:, None])\n",
    "\n",
    "    # Compute MAP@3 manually\n",
    "    map3 = 0\n",
    "    for i in range(len(labels)):\n",
    "        if match[i, 0]:\n",
    "            map3 += 1.0\n",
    "        elif match[i, 1]:\n",
    "            map3 += 1.0 / 2\n",
    "        elif match[i, 2]:\n",
    "            map3 += 1.0 / 3\n",
    "    return {\"map@3\": map3 / len(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:49:07.677385Z",
     "iopub.status.busy": "2025-07-26T10:49:07.676679Z",
     "iopub.status.idle": "2025-07-26T10:49:19.64657Z",
     "shell.execute_reply": "2025-07-26T10:49:19.646016Z",
     "shell.execute_reply.started": "2025-07-26T10:49:07.677359Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_map3,\n",
    ")\n",
    "\n",
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:49:19.648083Z",
     "iopub.status.busy": "2025-07-26T10:49:19.647804Z",
     "iopub.status.idle": "2025-07-26T10:49:19.662334Z",
     "shell.execute_reply": "2025-07-26T10:49:19.661577Z",
     "shell.execute_reply.started": "2025-07-26T10:49:19.64806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/map-charting-student-math-misunderstandings/test.csv')\n",
    "print( test.shape )\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:49:19.663471Z",
     "iopub.status.busy": "2025-07-26T10:49:19.663227Z",
     "iopub.status.idle": "2025-07-26T10:49:19.676264Z",
     "shell.execute_reply": "2025-07-26T10:49:19.675577Z",
     "shell.execute_reply.started": "2025-07-26T10:49:19.663448Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test = test.merge(correct, on=['QuestionId','MC_Answer'], how='left')\n",
    "test.is_correct = test.is_correct.fillna(0)\n",
    "\n",
    "test['text'] = test.apply(format_input,axis=1)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:49:19.678012Z",
     "iopub.status.busy": "2025-07-26T10:49:19.677736Z",
     "iopub.status.idle": "2025-07-26T10:49:20.062506Z",
     "shell.execute_reply": "2025-07-26T10:49:20.061868Z",
     "shell.execute_reply.started": "2025-07-26T10:49:19.677996Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds_test = Dataset.from_pandas(test[['text']])\n",
    "ds_test = ds_test.map(tokenize, batched=True)\n",
    "\n",
    "predictions = trainer.predict(ds_test)\n",
    "probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:49:20.063415Z",
     "iopub.status.busy": "2025-07-26T10:49:20.063193Z",
     "iopub.status.idle": "2025-07-26T10:49:20.074671Z",
     "shell.execute_reply": "2025-07-26T10:49:20.07389Z",
     "shell.execute_reply.started": "2025-07-26T10:49:20.06339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get top 3 predicted class indices\n",
    "top3 = np.argsort(-probs, axis=1)[:, :]   # shape: [num_samples, 3]\n",
    "\n",
    "# Decode numeric class indices to original string labels\n",
    "flat_top3 = top3.flatten()\n",
    "decoded_labels = le.inverse_transform(flat_top3)\n",
    "top3_labels = decoded_labels.reshape(top3.shape)\n",
    "\n",
    "# Join 3 labels per row with space\n",
    "joined_preds = [\"|\".join(row) for row in top3_labels]\n",
    "\n",
    "# Save submission\n",
    "sub = pd.DataFrame({\n",
    "    \"row_id\": test.row_id.values,\n",
    "    \"Category:Misconception\": joined_preds\n",
    "})\n",
    "sub.to_csv(\"submission_modern.csv\", index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:49:20.075741Z",
     "iopub.status.busy": "2025-07-26T10:49:20.075459Z",
     "iopub.status.idle": "2025-07-26T10:49:20.095793Z",
     "shell.execute_reply": "2025-07-26T10:49:20.095281Z",
     "shell.execute_reply.started": "2025-07-26T10:49:20.075716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sub.iloc[0]['Category:Misconception']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:49:30.101461Z",
     "iopub.status.busy": "2025-07-26T10:49:30.101004Z",
     "iopub.status.idle": "2025-07-26T10:49:30.655263Z",
     "shell.execute_reply": "2025-07-26T10:49:30.654484Z",
     "shell.execute_reply.started": "2025-07-26T10:49:30.10144Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "del top3_labels, flat_top3, decoded_labels, top3, test, ds_test\n",
    "del training_args, train_ds, val_ds, model, trainer, predictions, probs\n",
    "# Delete any other lingering references\n",
    "for obj in list(globals().keys()):\n",
    "    if isinstance(globals()[obj], torch.nn.Module) or isinstance(globals()[obj], torch.Tensor):\n",
    "        del globals()[obj]\n",
    "\n",
    "# Dọn sạch autograd\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Nếu dùng nhiều GPU, làm thêm bước này để clear hết:\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "# In ra kiểm tra\n",
    "print(\"Memory allocated:\", torch.cuda.memory_allocated())\n",
    "print(\"Memory reserved:\", torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:49:32.600358Z",
     "iopub.status.busy": "2025-07-26T10:49:32.600076Z",
     "iopub.status.idle": "2025-07-26T10:49:33.005723Z",
     "shell.execute_reply": "2025-07-26T10:49:33.005014Z",
     "shell.execute_reply.started": "2025-07-26T10:49:32.600338Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for obj in list(globals().keys()):\n",
    "    if isinstance(globals()[obj], torch.nn.Module) or isinstance(globals()[obj], torch.Tensor):\n",
    "        del globals()[obj]\n",
    "\n",
    "# Dọn sạch autograd\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Nếu dùng nhiều GPU, làm thêm bước này để clear hết:\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "# In ra kiểm tra\n",
    "print(\"Memory allocated:\", torch.cuda.memory_allocated())\n",
    "print(\"Memory reserved:\", torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:49:34.450541Z",
     "iopub.status.busy": "2025-07-26T10:49:34.450041Z",
     "iopub.status.idle": "2025-07-26T10:49:34.846022Z",
     "shell.execute_reply": "2025-07-26T10:49:34.845341Z",
     "shell.execute_reply.started": "2025-07-26T10:49:34.450519Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for obj in list(globals().keys()):\n",
    "    if isinstance(globals()[obj], torch.nn.Module) or isinstance(globals()[obj], torch.Tensor):\n",
    "        del globals()[obj]\n",
    "\n",
    "# Dọn sạch autograd\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Nếu dùng nhiều GPU, làm thêm bước này để clear hết:\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "# In ra kiểm tra\n",
    "print(\"Memory allocated:\", torch.cuda.memory_allocated())\n",
    "print(\"Memory reserved:\", torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:49:36.366075Z",
     "iopub.status.busy": "2025-07-26T10:49:36.365765Z",
     "iopub.status.idle": "2025-07-26T10:49:36.771617Z",
     "shell.execute_reply": "2025-07-26T10:49:36.770863Z",
     "shell.execute_reply.started": "2025-07-26T10:49:36.366054Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for obj in list(globals().keys()):\n",
    "    if isinstance(globals()[obj], torch.nn.Module) or isinstance(globals()[obj], torch.Tensor):\n",
    "        del globals()[obj]\n",
    "\n",
    "# Dọn sạch autograd\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# Nếu dùng nhiều GPU, làm thêm bước này để clear hết:\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "# In ra kiểm tra\n",
    "print(\"Memory allocated:\", torch.cuda.memory_allocated())\n",
    "print(\"Memory reserved:\", torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ENSEMBLE EVERYTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:59:43.490725Z",
     "iopub.status.busy": "2025-07-26T10:59:43.490251Z",
     "iopub.status.idle": "2025-07-26T10:59:43.496701Z",
     "shell.execute_reply": "2025-07-26T10:59:43.496055Z",
     "shell.execute_reply.started": "2025-07-26T10:59:43.490705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_top_k_ensemble(l1, l2, l3, k=3):\n",
    "    list1, list2, list3 = l1.split('|'), l2.split('|'), l3.split('|')\n",
    "    weights = [4, 4, 4]  # độ tin cậy: list1 > list2 > list3\n",
    "    lists = [list1, list2, list3]\n",
    "    score = defaultdict(int)\n",
    "\n",
    "    for i, lst in enumerate(lists):\n",
    "        weight = weights[i]\n",
    "        for rank, item in enumerate(lst):\n",
    "            score[item] += (len(lst) - rank) * weight\n",
    "\n",
    "    # Sắp xếp theo điểm giảm dần\n",
    "    sorted_items = sorted(score.items(), key=lambda x: -x[1])\n",
    "    return ' '.join([item for item, _ in sorted_items[:k]])\n",
    "\n",
    "list1 = 'a|b|d|f'\n",
    "list2 = 'b|c|a|e'\n",
    "list3 = 'c|e|b'\n",
    "\n",
    "print(get_top_k_ensemble(list1, list2, list3, k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T11:04:29.782981Z",
     "iopub.status.busy": "2025-07-26T11:04:29.782349Z",
     "iopub.status.idle": "2025-07-26T11:04:29.802319Z",
     "shell.execute_reply": "2025-07-26T11:04:29.8016Z",
     "shell.execute_reply.started": "2025-07-26T11:04:29.782956Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('submission_gemma.csv').rename(columns = {'Category:Misconception':'Category:Misconception_gemma'})\n",
    "df2 = pd.read_csv('submission_ettin.csv').rename(columns = {'Category:Misconception':'Category:Misconception_ettin'})\n",
    "df3 = pd.read_csv('submission_modern.csv').rename(columns = {'Category:Misconception':'Category:Misconception_modern'})\n",
    "\n",
    "df = pd.merge(df1, df2, on = 'row_id', how = 'inner')\n",
    "df = pd.merge(df, df3, on = 'row_id', how = 'inner')\n",
    "df['Category:Misconception'] = df.apply(lambda x: get_top_k_ensemble(x['Category:Misconception_gemma'], x['Category:Misconception_ettin'], x['Category:Misconception_modern']), axis = 1)\n",
    "df[['row_id', 'Category:Misconception']].to_csv('submission.csv', index = False)\n",
    "pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12957508,
     "sourceId": 104383,
     "sourceType": "competition"
    },
    {
     "datasetId": 2804156,
     "sourceId": 4838716,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4675929,
     "sourceId": 7951074,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7876222,
     "sourceId": 12482600,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7876267,
     "sourceId": 12482664,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7889801,
     "sourceId": 12501066,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7902972,
     "sourceId": 12520079,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7930680,
     "sourceId": 12559632,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7930694,
     "sourceId": 12559652,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 250164766,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 250240084,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 250244223,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 250376941,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 250442799,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 222398,
     "modelInstanceId": 239467,
     "sourceId": 282742,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 488.24026,
   "end_time": "2025-07-23T09:35:25.786365",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-23T09:27:17.546105",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0c26753c7cd9477090f4e54da5a5d9df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0dd865443ab647fbb1fa7712c2442eb6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ac9811f2ab74e268298b6e8c5e380ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1d8c435cac7a402bb5851b7e4e3d08c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2103e65a84fd4ff3bbc0644be7dc1491": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2213228fa0d64f59ae800b6cd4fa0024": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2e868a9d3dee43a7879209de3e26e3cb",
        "IPY_MODEL_f105d173a94647a8ac4cf529166a56e9",
        "IPY_MODEL_9eb2f938791a4d1d917a8c349e89490c"
       ],
       "layout": "IPY_MODEL_e866c2f5ff304064aefd2fe913dba8e9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "244ec229abe84dcc90429ff11b3321ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2b2e627e283441df846d586bf04f1faf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2e868a9d3dee43a7879209de3e26e3cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9577c0390f2b40d697efc85c52f9fede",
       "placeholder": "​",
       "style": "IPY_MODEL_a07414cea2a9453cb72f138d269b3077",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "38f5961db6744f3792b62b3bc6e77df2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "39d058dc858e41a7bcc91ad1ac8bf2e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fe276264bf50461c964705e75b64c649",
       "placeholder": "​",
       "style": "IPY_MODEL_0c26753c7cd9477090f4e54da5a5d9df",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "4ca40d828a6b4580967370019d520a8e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4eca885cf0714ca8b40901ed148e781c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "51f466ba750640c48eecb5fa6526849a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a06180301494f768aea39a27769dbc7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5fc61555de8e440383212f23a86feec6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "70d0f51605224e0b928d7f61478b86da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "786e517428ab41b6952da0f4acf92e2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0dd865443ab647fbb1fa7712c2442eb6",
       "max": 1024,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_83ee376b868d4e75a37a214f0d9a2cc1",
       "tabbable": null,
       "tooltip": null,
       "value": 1024
      }
     },
     "81505f5c4c464f988f2ddf0bae570a6e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "83ee376b868d4e75a37a214f0d9a2cc1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8704ef664eec498f90df3826c0d35c94": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8eb0c86b662549b8bff8b5c231aaad34": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cb37ea7a40394d59944efa316cb0dac5",
       "placeholder": "​",
       "style": "IPY_MODEL_81505f5c4c464f988f2ddf0bae570a6e",
       "tabbable": null,
       "tooltip": null,
       "value": " 3/3 [00:00&lt;00:00, 212.36 examples/s]"
      }
     },
     "9577c0390f2b40d697efc85c52f9fede": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9eb2f938791a4d1d917a8c349e89490c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4ca40d828a6b4580967370019d520a8e",
       "placeholder": "​",
       "style": "IPY_MODEL_2b2e627e283441df846d586bf04f1faf",
       "tabbable": null,
       "tooltip": null,
       "value": " 1024/1024 [00:00&lt;00:00, 6928.62 examples/s]"
      }
     },
     "9f76258a21dd42f08b9084c1a9c8fa3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_39d058dc858e41a7bcc91ad1ac8bf2e4",
        "IPY_MODEL_786e517428ab41b6952da0f4acf92e2c",
        "IPY_MODEL_a32d52b7a7a04df8ac1891fc02b9720d"
       ],
       "layout": "IPY_MODEL_5fc61555de8e440383212f23a86feec6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a07414cea2a9453cb72f138d269b3077": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a32d52b7a7a04df8ac1891fc02b9720d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d3fcab27710b4c44b6c7272245cd065e",
       "placeholder": "​",
       "style": "IPY_MODEL_d6d72f5a62624ecdb7caf3891b30f432",
       "tabbable": null,
       "tooltip": null,
       "value": " 1024/1024 [00:00&lt;00:00, 5366.10 examples/s]"
      }
     },
     "a619829b3f0e4f029acd5bae6765fa5d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a86e0231a1b34e20aa0c4516ff74f8ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d8dd297a2fc442ed863090ee2cc2eabf",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2103e65a84fd4ff3bbc0644be7dc1491",
       "tabbable": null,
       "tooltip": null,
       "value": 4
      }
     },
     "ac49d53cb50e4a18babb251ad2057bd2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c0afa6ead02c4df48ece53c8953063dc",
        "IPY_MODEL_a86e0231a1b34e20aa0c4516ff74f8ec",
        "IPY_MODEL_ea2a394c12ec4a06b46206158e686389"
       ],
       "layout": "IPY_MODEL_51f466ba750640c48eecb5fa6526849a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c0afa6ead02c4df48ece53c8953063dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a619829b3f0e4f029acd5bae6765fa5d",
       "placeholder": "​",
       "style": "IPY_MODEL_244ec229abe84dcc90429ff11b3321ad",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "cb37ea7a40394d59944efa316cb0dac5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cbcac099d7014868a324d0b03a6bbfd1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc1082082f3b493d84ca2183be20b76d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ceaae78b4bd54cd1a275c899b5572d2c",
        "IPY_MODEL_d62c51e6c3a14aa9a7909254fff5ff16",
        "IPY_MODEL_8eb0c86b662549b8bff8b5c231aaad34"
       ],
       "layout": "IPY_MODEL_cbcac099d7014868a324d0b03a6bbfd1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ceaae78b4bd54cd1a275c899b5572d2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4eca885cf0714ca8b40901ed148e781c",
       "placeholder": "​",
       "style": "IPY_MODEL_70d0f51605224e0b928d7f61478b86da",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "d3fcab27710b4c44b6c7272245cd065e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d62c51e6c3a14aa9a7909254fff5ff16": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d6831d9a397f48b3ac8f05ff9b2b057c",
       "max": 3,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_38f5961db6744f3792b62b3bc6e77df2",
       "tabbable": null,
       "tooltip": null,
       "value": 3
      }
     },
     "d6831d9a397f48b3ac8f05ff9b2b057c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d6d72f5a62624ecdb7caf3891b30f432": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d8dd297a2fc442ed863090ee2cc2eabf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e866c2f5ff304064aefd2fe913dba8e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ea2a394c12ec4a06b46206158e686389": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1d8c435cac7a402bb5851b7e4e3d08c2",
       "placeholder": "​",
       "style": "IPY_MODEL_5a06180301494f768aea39a27769dbc7",
       "tabbable": null,
       "tooltip": null,
       "value": " 4/4 [02:02&lt;00:00, 29.23s/it]"
      }
     },
     "f105d173a94647a8ac4cf529166a56e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8704ef664eec498f90df3826c0d35c94",
       "max": 1024,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1ac9811f2ab74e268298b6e8c5e380ff",
       "tabbable": null,
       "tooltip": null,
       "value": 1024
      }
     },
     "fe276264bf50461c964705e75b64c649": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
